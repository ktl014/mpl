WARNING: Logging before InitGoogleLogging() is written to STDERR
I0828 14:17:36.691664  4902 solver.cpp:44] Initializing solver from parameters: 
test_iter: 20
test_interval: 250
base_lr: 0.001
display: 20
max_iter: 5000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1500
snapshot: 5000
snapshot_prefix: "caffenet_train"
solver_mode: GPU
net: "caffenet/train_val.prototxt"
I0828 14:17:36.692561  4902 solver.cpp:87] Creating training net from net file: caffenet/train_val.prototxt
I0828 14:17:36.709944  4902 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0828 14:17:36.709975  4902 net.cpp:296] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0828 14:17:36.710188  4902 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "train.LMDB"
    batch_size: 256
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0828 14:17:36.710314  4902 layer_factory.hpp:77] Creating layer data
I0828 14:17:36.712149  4902 db_lmdb.cpp:35] Opened lmdb train.LMDB
I0828 14:17:36.712306  4902 net.cpp:86] Creating Layer data
I0828 14:17:36.712323  4902 net.cpp:382] data -> data
I0828 14:17:36.712359  4902 net.cpp:382] data -> label
I0828 14:17:36.713950  4902 data_layer.cpp:45] output data size: 256,3,227,227
I0828 14:17:37.189167  4902 net.cpp:124] Setting up data
I0828 14:17:37.189226  4902 net.cpp:131] Top shape: 256 3 227 227 (39574272)
I0828 14:17:37.189235  4902 net.cpp:131] Top shape: 256 (256)
I0828 14:17:37.189240  4902 net.cpp:139] Memory required for data: 158298112
I0828 14:17:37.189250  4902 layer_factory.hpp:77] Creating layer conv1
I0828 14:17:37.189280  4902 net.cpp:86] Creating Layer conv1
I0828 14:17:37.189287  4902 net.cpp:408] conv1 <- data
I0828 14:17:37.189302  4902 net.cpp:382] conv1 -> conv1
I0828 14:17:37.757033  4902 net.cpp:124] Setting up conv1
I0828 14:17:37.757091  4902 net.cpp:131] Top shape: 256 96 55 55 (74342400)
I0828 14:17:37.757097  4902 net.cpp:139] Memory required for data: 455667712
I0828 14:17:37.757125  4902 layer_factory.hpp:77] Creating layer relu1
I0828 14:17:37.757158  4902 net.cpp:86] Creating Layer relu1
I0828 14:17:37.757166  4902 net.cpp:408] relu1 <- conv1
I0828 14:17:37.757174  4902 net.cpp:369] relu1 -> conv1 (in-place)
I0828 14:17:37.761884  4902 net.cpp:124] Setting up relu1
I0828 14:17:37.761914  4902 net.cpp:131] Top shape: 256 96 55 55 (74342400)
I0828 14:17:37.761919  4902 net.cpp:139] Memory required for data: 753037312
I0828 14:17:37.761925  4902 layer_factory.hpp:77] Creating layer pool1
I0828 14:17:37.761937  4902 net.cpp:86] Creating Layer pool1
I0828 14:17:37.761942  4902 net.cpp:408] pool1 <- conv1
I0828 14:17:37.761950  4902 net.cpp:382] pool1 -> pool1
I0828 14:17:37.762003  4902 net.cpp:124] Setting up pool1
I0828 14:17:37.762015  4902 net.cpp:131] Top shape: 256 96 27 27 (17915904)
I0828 14:17:37.762022  4902 net.cpp:139] Memory required for data: 824700928
I0828 14:17:37.762027  4902 layer_factory.hpp:77] Creating layer norm1
I0828 14:17:37.762040  4902 net.cpp:86] Creating Layer norm1
I0828 14:17:37.762046  4902 net.cpp:408] norm1 <- pool1
I0828 14:17:37.762054  4902 net.cpp:382] norm1 -> norm1
I0828 14:17:37.764166  4902 net.cpp:124] Setting up norm1
I0828 14:17:37.764183  4902 net.cpp:131] Top shape: 256 96 27 27 (17915904)
I0828 14:17:37.764189  4902 net.cpp:139] Memory required for data: 896364544
I0828 14:17:37.764194  4902 layer_factory.hpp:77] Creating layer conv2
I0828 14:17:37.764214  4902 net.cpp:86] Creating Layer conv2
I0828 14:17:37.764219  4902 net.cpp:408] conv2 <- norm1
I0828 14:17:37.764227  4902 net.cpp:382] conv2 -> conv2
I0828 14:17:37.786803  4902 net.cpp:124] Setting up conv2
I0828 14:17:37.786828  4902 net.cpp:131] Top shape: 256 256 27 27 (47775744)
I0828 14:17:37.786837  4902 net.cpp:139] Memory required for data: 1087467520
I0828 14:17:37.786861  4902 layer_factory.hpp:77] Creating layer relu2
I0828 14:17:37.786877  4902 net.cpp:86] Creating Layer relu2
I0828 14:17:37.786888  4902 net.cpp:408] relu2 <- conv2
I0828 14:17:37.786905  4902 net.cpp:369] relu2 -> conv2 (in-place)
I0828 14:17:37.788046  4902 net.cpp:124] Setting up relu2
I0828 14:17:37.788066  4902 net.cpp:131] Top shape: 256 256 27 27 (47775744)
I0828 14:17:37.788074  4902 net.cpp:139] Memory required for data: 1278570496
I0828 14:17:37.788085  4902 layer_factory.hpp:77] Creating layer pool2
I0828 14:17:37.788100  4902 net.cpp:86] Creating Layer pool2
I0828 14:17:37.788113  4902 net.cpp:408] pool2 <- conv2
I0828 14:17:37.788126  4902 net.cpp:382] pool2 -> pool2
I0828 14:17:37.788199  4902 net.cpp:124] Setting up pool2
I0828 14:17:37.788219  4902 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0828 14:17:37.788229  4902 net.cpp:139] Memory required for data: 1322872832
I0828 14:17:37.788239  4902 layer_factory.hpp:77] Creating layer norm2
I0828 14:17:37.788255  4902 net.cpp:86] Creating Layer norm2
I0828 14:17:37.788266  4902 net.cpp:408] norm2 <- pool2
I0828 14:17:37.788282  4902 net.cpp:382] norm2 -> norm2
I0828 14:17:37.790320  4902 net.cpp:124] Setting up norm2
I0828 14:17:37.790343  4902 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0828 14:17:37.790354  4902 net.cpp:139] Memory required for data: 1367175168
I0828 14:17:37.790364  4902 layer_factory.hpp:77] Creating layer conv3
I0828 14:17:37.790387  4902 net.cpp:86] Creating Layer conv3
I0828 14:17:37.790400  4902 net.cpp:408] conv3 <- norm2
I0828 14:17:37.790417  4902 net.cpp:382] conv3 -> conv3
I0828 14:17:37.839246  4902 net.cpp:124] Setting up conv3
I0828 14:17:37.839267  4902 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0828 14:17:37.839272  4902 net.cpp:139] Memory required for data: 1433628672
I0828 14:17:37.839285  4902 layer_factory.hpp:77] Creating layer relu3
I0828 14:17:37.839299  4902 net.cpp:86] Creating Layer relu3
I0828 14:17:37.839306  4902 net.cpp:408] relu3 <- conv3
I0828 14:17:37.839313  4902 net.cpp:369] relu3 -> conv3 (in-place)
I0828 14:17:37.841856  4902 net.cpp:124] Setting up relu3
I0828 14:17:37.841871  4902 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0828 14:17:37.841876  4902 net.cpp:139] Memory required for data: 1500082176
I0828 14:17:37.841881  4902 layer_factory.hpp:77] Creating layer conv4
I0828 14:17:37.841897  4902 net.cpp:86] Creating Layer conv4
I0828 14:17:37.841903  4902 net.cpp:408] conv4 <- conv3
I0828 14:17:37.841912  4902 net.cpp:382] conv4 -> conv4
I0828 14:17:37.881634  4902 net.cpp:124] Setting up conv4
I0828 14:17:37.881654  4902 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0828 14:17:37.881659  4902 net.cpp:139] Memory required for data: 1566535680
I0828 14:17:37.881669  4902 layer_factory.hpp:77] Creating layer relu4
I0828 14:17:37.881682  4902 net.cpp:86] Creating Layer relu4
I0828 14:17:37.881690  4902 net.cpp:408] relu4 <- conv4
I0828 14:17:37.881696  4902 net.cpp:369] relu4 -> conv4 (in-place)
I0828 14:17:37.884158  4902 net.cpp:124] Setting up relu4
I0828 14:17:37.884174  4902 net.cpp:131] Top shape: 256 384 13 13 (16613376)
I0828 14:17:37.884179  4902 net.cpp:139] Memory required for data: 1632989184
I0828 14:17:37.884184  4902 layer_factory.hpp:77] Creating layer conv5
I0828 14:17:37.884199  4902 net.cpp:86] Creating Layer conv5
I0828 14:17:37.884204  4902 net.cpp:408] conv5 <- conv4
I0828 14:17:37.884215  4902 net.cpp:382] conv5 -> conv5
I0828 14:17:37.916887  4902 net.cpp:124] Setting up conv5
I0828 14:17:37.916908  4902 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0828 14:17:37.916914  4902 net.cpp:139] Memory required for data: 1677291520
I0828 14:17:37.916931  4902 layer_factory.hpp:77] Creating layer relu5
I0828 14:17:37.916944  4902 net.cpp:86] Creating Layer relu5
I0828 14:17:37.916950  4902 net.cpp:408] relu5 <- conv5
I0828 14:17:37.916957  4902 net.cpp:369] relu5 -> conv5 (in-place)
I0828 14:17:37.917179  4902 net.cpp:124] Setting up relu5
I0828 14:17:37.917194  4902 net.cpp:131] Top shape: 256 256 13 13 (11075584)
I0828 14:17:37.917201  4902 net.cpp:139] Memory required for data: 1721593856
I0828 14:17:37.917207  4902 layer_factory.hpp:77] Creating layer pool5
I0828 14:17:37.917218  4902 net.cpp:86] Creating Layer pool5
I0828 14:17:37.917224  4902 net.cpp:408] pool5 <- conv5
I0828 14:17:37.917232  4902 net.cpp:382] pool5 -> pool5
I0828 14:17:37.917296  4902 net.cpp:124] Setting up pool5
I0828 14:17:37.917309  4902 net.cpp:131] Top shape: 256 256 6 6 (2359296)
I0828 14:17:37.917315  4902 net.cpp:139] Memory required for data: 1731031040
I0828 14:17:37.917320  4902 layer_factory.hpp:77] Creating layer fc6
I0828 14:17:37.917348  4902 net.cpp:86] Creating Layer fc6
I0828 14:17:37.917356  4902 net.cpp:408] fc6 <- pool5
I0828 14:17:37.917366  4902 net.cpp:382] fc6 -> fc6
I0828 14:17:39.401329  4902 net.cpp:124] Setting up fc6
I0828 14:17:39.401401  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:39.401407  4902 net.cpp:139] Memory required for data: 1735225344
I0828 14:17:39.401428  4902 layer_factory.hpp:77] Creating layer relu6
I0828 14:17:39.401465  4902 net.cpp:86] Creating Layer relu6
I0828 14:17:39.401477  4902 net.cpp:408] relu6 <- fc6
I0828 14:17:39.401491  4902 net.cpp:369] relu6 -> fc6 (in-place)
I0828 14:17:39.402755  4902 net.cpp:124] Setting up relu6
I0828 14:17:39.402772  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:39.402778  4902 net.cpp:139] Memory required for data: 1739419648
I0828 14:17:39.402783  4902 layer_factory.hpp:77] Creating layer drop6
I0828 14:17:39.402818  4902 net.cpp:86] Creating Layer drop6
I0828 14:17:39.402827  4902 net.cpp:408] drop6 <- fc6
I0828 14:17:39.402834  4902 net.cpp:369] drop6 -> fc6 (in-place)
I0828 14:17:39.402868  4902 net.cpp:124] Setting up drop6
I0828 14:17:39.402878  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:39.402884  4902 net.cpp:139] Memory required for data: 1743613952
I0828 14:17:39.402889  4902 layer_factory.hpp:77] Creating layer fc7
I0828 14:17:39.402912  4902 net.cpp:86] Creating Layer fc7
I0828 14:17:39.402920  4902 net.cpp:408] fc7 <- fc6
I0828 14:17:39.402930  4902 net.cpp:382] fc7 -> fc7
I0828 14:17:40.063350  4902 net.cpp:124] Setting up fc7
I0828 14:17:40.063397  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:40.063403  4902 net.cpp:139] Memory required for data: 1747808256
I0828 14:17:40.063422  4902 layer_factory.hpp:77] Creating layer relu7
I0828 14:17:40.063441  4902 net.cpp:86] Creating Layer relu7
I0828 14:17:40.063449  4902 net.cpp:408] relu7 <- fc7
I0828 14:17:40.063462  4902 net.cpp:369] relu7 -> fc7 (in-place)
I0828 14:17:40.064172  4902 net.cpp:124] Setting up relu7
I0828 14:17:40.064188  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:40.064195  4902 net.cpp:139] Memory required for data: 1752002560
I0828 14:17:40.064203  4902 layer_factory.hpp:77] Creating layer drop7
I0828 14:17:40.064220  4902 net.cpp:86] Creating Layer drop7
I0828 14:17:40.064227  4902 net.cpp:408] drop7 <- fc7
I0828 14:17:40.064234  4902 net.cpp:369] drop7 -> fc7 (in-place)
I0828 14:17:40.064270  4902 net.cpp:124] Setting up drop7
I0828 14:17:40.064280  4902 net.cpp:131] Top shape: 256 4096 (1048576)
I0828 14:17:40.064287  4902 net.cpp:139] Memory required for data: 1756196864
I0828 14:17:40.064291  4902 layer_factory.hpp:77] Creating layer fc8
I0828 14:17:40.064304  4902 net.cpp:86] Creating Layer fc8
I0828 14:17:40.064309  4902 net.cpp:408] fc8 <- fc7
I0828 14:17:40.064321  4902 net.cpp:382] fc8 -> fc8
I0828 14:17:40.065485  4902 net.cpp:124] Setting up fc8
I0828 14:17:40.065506  4902 net.cpp:131] Top shape: 256 2 (512)
I0828 14:17:40.065512  4902 net.cpp:139] Memory required for data: 1756198912
I0828 14:17:40.065522  4902 layer_factory.hpp:77] Creating layer loss
I0828 14:17:40.065551  4902 net.cpp:86] Creating Layer loss
I0828 14:17:40.065558  4902 net.cpp:408] loss <- fc8
I0828 14:17:40.065565  4902 net.cpp:408] loss <- label
I0828 14:17:40.065573  4902 net.cpp:382] loss -> loss
I0828 14:17:40.065588  4902 layer_factory.hpp:77] Creating layer loss
I0828 14:17:40.065943  4902 net.cpp:124] Setting up loss
I0828 14:17:40.065958  4902 net.cpp:131] Top shape: (1)
I0828 14:17:40.065964  4902 net.cpp:134]     with loss weight 1
I0828 14:17:40.065990  4902 net.cpp:139] Memory required for data: 1756198916
I0828 14:17:40.065996  4902 net.cpp:200] loss needs backward computation.
I0828 14:17:40.066002  4902 net.cpp:200] fc8 needs backward computation.
I0828 14:17:40.066006  4902 net.cpp:200] drop7 needs backward computation.
I0828 14:17:40.066010  4902 net.cpp:200] relu7 needs backward computation.
I0828 14:17:40.066015  4902 net.cpp:200] fc7 needs backward computation.
I0828 14:17:40.066020  4902 net.cpp:200] drop6 needs backward computation.
I0828 14:17:40.066025  4902 net.cpp:200] relu6 needs backward computation.
I0828 14:17:40.066028  4902 net.cpp:200] fc6 needs backward computation.
I0828 14:17:40.066033  4902 net.cpp:200] pool5 needs backward computation.
I0828 14:17:40.066040  4902 net.cpp:200] relu5 needs backward computation.
I0828 14:17:40.066045  4902 net.cpp:200] conv5 needs backward computation.
I0828 14:17:40.066054  4902 net.cpp:200] relu4 needs backward computation.
I0828 14:17:40.066061  4902 net.cpp:200] conv4 needs backward computation.
I0828 14:17:40.066066  4902 net.cpp:200] relu3 needs backward computation.
I0828 14:17:40.066073  4902 net.cpp:200] conv3 needs backward computation.
I0828 14:17:40.066081  4902 net.cpp:200] norm2 needs backward computation.
I0828 14:17:40.066090  4902 net.cpp:200] pool2 needs backward computation.
I0828 14:17:40.066097  4902 net.cpp:200] relu2 needs backward computation.
I0828 14:17:40.066102  4902 net.cpp:200] conv2 needs backward computation.
I0828 14:17:40.066108  4902 net.cpp:200] norm1 needs backward computation.
I0828 14:17:40.066123  4902 net.cpp:200] pool1 needs backward computation.
I0828 14:17:40.066135  4902 net.cpp:200] relu1 needs backward computation.
I0828 14:17:40.066143  4902 net.cpp:200] conv1 needs backward computation.
I0828 14:17:40.066149  4902 net.cpp:202] data does not need backward computation.
I0828 14:17:40.066155  4902 net.cpp:244] This network produces output loss
I0828 14:17:40.066174  4902 net.cpp:257] Network initialization done.
I0828 14:17:40.067512  4902 solver.cpp:173] Creating test net (#0) specified by net file: caffenet/train_val.prototxt
I0828 14:17:40.067579  4902 net.cpp:296] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0828 14:17:40.067836  4902 net.cpp:53] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_value: 104
    mean_value: 117
    mean_value: 123
  }
  data_param {
    source: "val.LMDB"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
    weight_filler {
      type: "gaussian"
      std: 0.005
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0828 14:17:40.067981  4902 layer_factory.hpp:77] Creating layer data
I0828 14:17:40.069793  4902 db_lmdb.cpp:35] Opened lmdb val.LMDB
I0828 14:17:40.069947  4902 net.cpp:86] Creating Layer data
I0828 14:17:40.069962  4902 net.cpp:382] data -> data
I0828 14:17:40.069977  4902 net.cpp:382] data -> label
I0828 14:17:40.070381  4902 data_layer.cpp:45] output data size: 50,3,227,227
I0828 14:17:40.186341  4902 net.cpp:124] Setting up data
I0828 14:17:40.186394  4902 net.cpp:131] Top shape: 50 3 227 227 (7729350)
I0828 14:17:40.186403  4902 net.cpp:131] Top shape: 50 (50)
I0828 14:17:40.186408  4902 net.cpp:139] Memory required for data: 30917600
I0828 14:17:40.186424  4902 layer_factory.hpp:77] Creating layer label_data_1_split
I0828 14:17:40.186449  4902 net.cpp:86] Creating Layer label_data_1_split
I0828 14:17:40.186458  4902 net.cpp:408] label_data_1_split <- label
I0828 14:17:40.186471  4902 net.cpp:382] label_data_1_split -> label_data_1_split_0
I0828 14:17:40.186497  4902 net.cpp:382] label_data_1_split -> label_data_1_split_1
I0828 14:17:40.186887  4902 net.cpp:124] Setting up label_data_1_split
I0828 14:17:40.186949  4902 net.cpp:131] Top shape: 50 (50)
I0828 14:17:40.186965  4902 net.cpp:131] Top shape: 50 (50)
I0828 14:17:40.186978  4902 net.cpp:139] Memory required for data: 30918000
I0828 14:17:40.186993  4902 layer_factory.hpp:77] Creating layer conv1
I0828 14:17:40.187037  4902 net.cpp:86] Creating Layer conv1
I0828 14:17:40.187052  4902 net.cpp:408] conv1 <- data
I0828 14:17:40.187077  4902 net.cpp:382] conv1 -> conv1
I0828 14:17:40.196636  4902 net.cpp:124] Setting up conv1
I0828 14:17:40.196686  4902 net.cpp:131] Top shape: 50 96 55 55 (14520000)
I0828 14:17:40.196698  4902 net.cpp:139] Memory required for data: 88998000
I0828 14:17:40.196733  4902 layer_factory.hpp:77] Creating layer relu1
I0828 14:17:40.196764  4902 net.cpp:86] Creating Layer relu1
I0828 14:17:40.196789  4902 net.cpp:408] relu1 <- conv1
I0828 14:17:40.196817  4902 net.cpp:369] relu1 -> conv1 (in-place)
I0828 14:17:40.198181  4902 net.cpp:124] Setting up relu1
I0828 14:17:40.198212  4902 net.cpp:131] Top shape: 50 96 55 55 (14520000)
I0828 14:17:40.198223  4902 net.cpp:139] Memory required for data: 147078000
I0828 14:17:40.198233  4902 layer_factory.hpp:77] Creating layer pool1
I0828 14:17:40.198256  4902 net.cpp:86] Creating Layer pool1
I0828 14:17:40.198273  4902 net.cpp:408] pool1 <- conv1
I0828 14:17:40.198307  4902 net.cpp:382] pool1 -> pool1
I0828 14:17:40.198433  4902 net.cpp:124] Setting up pool1
I0828 14:17:40.198462  4902 net.cpp:131] Top shape: 50 96 27 27 (3499200)
I0828 14:17:40.198515  4902 net.cpp:139] Memory required for data: 161074800
I0828 14:17:40.198551  4902 layer_factory.hpp:77] Creating layer norm1
I0828 14:17:40.198583  4902 net.cpp:86] Creating Layer norm1
I0828 14:17:40.198596  4902 net.cpp:408] norm1 <- pool1
I0828 14:17:40.198612  4902 net.cpp:382] norm1 -> norm1
I0828 14:17:40.200464  4902 net.cpp:124] Setting up norm1
I0828 14:17:40.200495  4902 net.cpp:131] Top shape: 50 96 27 27 (3499200)
I0828 14:17:40.200505  4902 net.cpp:139] Memory required for data: 175071600
I0828 14:17:40.200517  4902 layer_factory.hpp:77] Creating layer conv2
I0828 14:17:40.200541  4902 net.cpp:86] Creating Layer conv2
I0828 14:17:40.200553  4902 net.cpp:408] conv2 <- norm1
I0828 14:17:40.200569  4902 net.cpp:382] conv2 -> conv2
I0828 14:17:40.233587  4902 net.cpp:124] Setting up conv2
I0828 14:17:40.233644  4902 net.cpp:131] Top shape: 50 256 27 27 (9331200)
I0828 14:17:40.233654  4902 net.cpp:139] Memory required for data: 212396400
I0828 14:17:40.233685  4902 layer_factory.hpp:77] Creating layer relu2
I0828 14:17:40.233705  4902 net.cpp:86] Creating Layer relu2
I0828 14:17:40.233713  4902 net.cpp:408] relu2 <- conv2
I0828 14:17:40.233731  4902 net.cpp:369] relu2 -> conv2 (in-place)
I0828 14:17:40.235656  4902 net.cpp:124] Setting up relu2
I0828 14:17:40.235677  4902 net.cpp:131] Top shape: 50 256 27 27 (9331200)
I0828 14:17:40.235684  4902 net.cpp:139] Memory required for data: 249721200
I0828 14:17:40.235692  4902 layer_factory.hpp:77] Creating layer pool2
I0828 14:17:40.235709  4902 net.cpp:86] Creating Layer pool2
I0828 14:17:40.235716  4902 net.cpp:408] pool2 <- conv2
I0828 14:17:40.235726  4902 net.cpp:382] pool2 -> pool2
I0828 14:17:40.235811  4902 net.cpp:124] Setting up pool2
I0828 14:17:40.235828  4902 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0828 14:17:40.235836  4902 net.cpp:139] Memory required for data: 258374000
I0828 14:17:40.235842  4902 layer_factory.hpp:77] Creating layer norm2
I0828 14:17:40.235857  4902 net.cpp:86] Creating Layer norm2
I0828 14:17:40.235864  4902 net.cpp:408] norm2 <- pool2
I0828 14:17:40.235877  4902 net.cpp:382] norm2 -> norm2
I0828 14:17:40.238703  4902 net.cpp:124] Setting up norm2
I0828 14:17:40.238726  4902 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0828 14:17:40.238734  4902 net.cpp:139] Memory required for data: 267026800
I0828 14:17:40.238740  4902 layer_factory.hpp:77] Creating layer conv3
I0828 14:17:40.238764  4902 net.cpp:86] Creating Layer conv3
I0828 14:17:40.238770  4902 net.cpp:408] conv3 <- norm2
I0828 14:17:40.238790  4902 net.cpp:382] conv3 -> conv3
I0828 14:17:40.287214  4902 net.cpp:124] Setting up conv3
I0828 14:17:40.287259  4902 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0828 14:17:40.287266  4902 net.cpp:139] Memory required for data: 280006000
I0828 14:17:40.287287  4902 layer_factory.hpp:77] Creating layer relu3
I0828 14:17:40.287305  4902 net.cpp:86] Creating Layer relu3
I0828 14:17:40.287313  4902 net.cpp:408] relu3 <- conv3
I0828 14:17:40.287324  4902 net.cpp:369] relu3 -> conv3 (in-place)
I0828 14:17:40.289718  4902 net.cpp:124] Setting up relu3
I0828 14:17:40.289736  4902 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0828 14:17:40.289742  4902 net.cpp:139] Memory required for data: 292985200
I0828 14:17:40.289747  4902 layer_factory.hpp:77] Creating layer conv4
I0828 14:17:40.289767  4902 net.cpp:86] Creating Layer conv4
I0828 14:17:40.289773  4902 net.cpp:408] conv4 <- conv3
I0828 14:17:40.289785  4902 net.cpp:382] conv4 -> conv4
I0828 14:17:40.329342  4902 net.cpp:124] Setting up conv4
I0828 14:17:40.329404  4902 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0828 14:17:40.329411  4902 net.cpp:139] Memory required for data: 305964400
I0828 14:17:40.329427  4902 layer_factory.hpp:77] Creating layer relu4
I0828 14:17:40.329447  4902 net.cpp:86] Creating Layer relu4
I0828 14:17:40.329460  4902 net.cpp:408] relu4 <- conv4
I0828 14:17:40.329478  4902 net.cpp:369] relu4 -> conv4 (in-place)
I0828 14:17:40.329727  4902 net.cpp:124] Setting up relu4
I0828 14:17:40.329742  4902 net.cpp:131] Top shape: 50 384 13 13 (3244800)
I0828 14:17:40.329747  4902 net.cpp:139] Memory required for data: 318943600
I0828 14:17:40.329753  4902 layer_factory.hpp:77] Creating layer conv5
I0828 14:17:40.329773  4902 net.cpp:86] Creating Layer conv5
I0828 14:17:40.329780  4902 net.cpp:408] conv5 <- conv4
I0828 14:17:40.329790  4902 net.cpp:382] conv5 -> conv5
I0828 14:17:40.355942  4902 net.cpp:124] Setting up conv5
I0828 14:17:40.355996  4902 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0828 14:17:40.356003  4902 net.cpp:139] Memory required for data: 327596400
I0828 14:17:40.356022  4902 layer_factory.hpp:77] Creating layer relu5
I0828 14:17:40.356036  4902 net.cpp:86] Creating Layer relu5
I0828 14:17:40.356042  4902 net.cpp:408] relu5 <- conv5
I0828 14:17:40.356065  4902 net.cpp:369] relu5 -> conv5 (in-place)
I0828 14:17:40.356307  4902 net.cpp:124] Setting up relu5
I0828 14:17:40.356323  4902 net.cpp:131] Top shape: 50 256 13 13 (2163200)
I0828 14:17:40.356334  4902 net.cpp:139] Memory required for data: 336249200
I0828 14:17:40.356346  4902 layer_factory.hpp:77] Creating layer pool5
I0828 14:17:40.356370  4902 net.cpp:86] Creating Layer pool5
I0828 14:17:40.356379  4902 net.cpp:408] pool5 <- conv5
I0828 14:17:40.356395  4902 net.cpp:382] pool5 -> pool5
I0828 14:17:40.356472  4902 net.cpp:124] Setting up pool5
I0828 14:17:40.356488  4902 net.cpp:131] Top shape: 50 256 6 6 (460800)
I0828 14:17:40.356498  4902 net.cpp:139] Memory required for data: 338092400
I0828 14:17:40.356509  4902 layer_factory.hpp:77] Creating layer fc6
I0828 14:17:40.356530  4902 net.cpp:86] Creating Layer fc6
I0828 14:17:40.356539  4902 net.cpp:408] fc6 <- pool5
I0828 14:17:40.356549  4902 net.cpp:382] fc6 -> fc6
I0828 14:17:41.776018  4902 net.cpp:124] Setting up fc6
I0828 14:17:41.776079  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:41.776085  4902 net.cpp:139] Memory required for data: 338911600
I0828 14:17:41.776100  4902 layer_factory.hpp:77] Creating layer relu6
I0828 14:17:41.776115  4902 net.cpp:86] Creating Layer relu6
I0828 14:17:41.776123  4902 net.cpp:408] relu6 <- fc6
I0828 14:17:41.776149  4902 net.cpp:369] relu6 -> fc6 (in-place)
I0828 14:17:41.776943  4902 net.cpp:124] Setting up relu6
I0828 14:17:41.776959  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:41.776963  4902 net.cpp:139] Memory required for data: 339730800
I0828 14:17:41.776983  4902 layer_factory.hpp:77] Creating layer drop6
I0828 14:17:41.777001  4902 net.cpp:86] Creating Layer drop6
I0828 14:17:41.777007  4902 net.cpp:408] drop6 <- fc6
I0828 14:17:41.777019  4902 net.cpp:369] drop6 -> fc6 (in-place)
I0828 14:17:41.777086  4902 net.cpp:124] Setting up drop6
I0828 14:17:41.777099  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:41.777109  4902 net.cpp:139] Memory required for data: 340550000
I0828 14:17:41.777120  4902 layer_factory.hpp:77] Creating layer fc7
I0828 14:17:41.777145  4902 net.cpp:86] Creating Layer fc7
I0828 14:17:41.777153  4902 net.cpp:408] fc7 <- fc6
I0828 14:17:41.777168  4902 net.cpp:382] fc7 -> fc7
I0828 14:17:42.391299  4902 net.cpp:124] Setting up fc7
I0828 14:17:42.391358  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:42.391364  4902 net.cpp:139] Memory required for data: 341369200
I0828 14:17:42.391379  4902 layer_factory.hpp:77] Creating layer relu7
I0828 14:17:42.391399  4902 net.cpp:86] Creating Layer relu7
I0828 14:17:42.391422  4902 net.cpp:408] relu7 <- fc7
I0828 14:17:42.391443  4902 net.cpp:369] relu7 -> fc7 (in-place)
I0828 14:17:42.391774  4902 net.cpp:124] Setting up relu7
I0828 14:17:42.391800  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:42.391805  4902 net.cpp:139] Memory required for data: 342188400
I0828 14:17:42.391810  4902 layer_factory.hpp:77] Creating layer drop7
I0828 14:17:42.391824  4902 net.cpp:86] Creating Layer drop7
I0828 14:17:42.391829  4902 net.cpp:408] drop7 <- fc7
I0828 14:17:42.391835  4902 net.cpp:369] drop7 -> fc7 (in-place)
I0828 14:17:42.391894  4902 net.cpp:124] Setting up drop7
I0828 14:17:42.391908  4902 net.cpp:131] Top shape: 50 4096 (204800)
I0828 14:17:42.391932  4902 net.cpp:139] Memory required for data: 343007600
I0828 14:17:42.391942  4902 layer_factory.hpp:77] Creating layer fc8
I0828 14:17:42.391960  4902 net.cpp:86] Creating Layer fc8
I0828 14:17:42.391968  4902 net.cpp:408] fc8 <- fc7
I0828 14:17:42.391983  4902 net.cpp:382] fc8 -> fc8
I0828 14:17:42.392465  4902 net.cpp:124] Setting up fc8
I0828 14:17:42.392479  4902 net.cpp:131] Top shape: 50 2 (100)
I0828 14:17:42.392499  4902 net.cpp:139] Memory required for data: 343008000
I0828 14:17:42.392510  4902 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0828 14:17:42.392521  4902 net.cpp:86] Creating Layer fc8_fc8_0_split
I0828 14:17:42.392527  4902 net.cpp:408] fc8_fc8_0_split <- fc8
I0828 14:17:42.392537  4902 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0828 14:17:42.392547  4902 net.cpp:382] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0828 14:17:42.392601  4902 net.cpp:124] Setting up fc8_fc8_0_split
I0828 14:17:42.392616  4902 net.cpp:131] Top shape: 50 2 (100)
I0828 14:17:42.392622  4902 net.cpp:131] Top shape: 50 2 (100)
I0828 14:17:42.392628  4902 net.cpp:139] Memory required for data: 343008800
I0828 14:17:42.392633  4902 layer_factory.hpp:77] Creating layer accuracy
I0828 14:17:42.392654  4902 net.cpp:86] Creating Layer accuracy
I0828 14:17:42.392662  4902 net.cpp:408] accuracy <- fc8_fc8_0_split_0
I0828 14:17:42.392668  4902 net.cpp:408] accuracy <- label_data_1_split_0
I0828 14:17:42.392683  4902 net.cpp:382] accuracy -> accuracy
I0828 14:17:42.392704  4902 net.cpp:124] Setting up accuracy
I0828 14:17:42.392715  4902 net.cpp:131] Top shape: (1)
I0828 14:17:42.392725  4902 net.cpp:139] Memory required for data: 343008804
I0828 14:17:42.392736  4902 layer_factory.hpp:77] Creating layer loss
I0828 14:17:42.392755  4902 net.cpp:86] Creating Layer loss
I0828 14:17:42.392765  4902 net.cpp:408] loss <- fc8_fc8_0_split_1
I0828 14:17:42.392774  4902 net.cpp:408] loss <- label_data_1_split_1
I0828 14:17:42.392789  4902 net.cpp:382] loss -> loss
I0828 14:17:42.392807  4902 layer_factory.hpp:77] Creating layer loss
I0828 14:17:42.394542  4902 net.cpp:124] Setting up loss
I0828 14:17:42.394562  4902 net.cpp:131] Top shape: (1)
I0828 14:17:42.394573  4902 net.cpp:134]     with loss weight 1
I0828 14:17:42.394598  4902 net.cpp:139] Memory required for data: 343008808
I0828 14:17:42.394609  4902 net.cpp:200] loss needs backward computation.
I0828 14:17:42.394620  4902 net.cpp:202] accuracy does not need backward computation.
I0828 14:17:42.394632  4902 net.cpp:200] fc8_fc8_0_split needs backward computation.
I0828 14:17:42.394644  4902 net.cpp:200] fc8 needs backward computation.
I0828 14:17:42.394654  4902 net.cpp:200] drop7 needs backward computation.
I0828 14:17:42.394665  4902 net.cpp:200] relu7 needs backward computation.
I0828 14:17:42.394675  4902 net.cpp:200] fc7 needs backward computation.
I0828 14:17:42.394685  4902 net.cpp:200] drop6 needs backward computation.
I0828 14:17:42.394695  4902 net.cpp:200] relu6 needs backward computation.
I0828 14:17:42.394704  4902 net.cpp:200] fc6 needs backward computation.
I0828 14:17:42.394716  4902 net.cpp:200] pool5 needs backward computation.
I0828 14:17:42.394726  4902 net.cpp:200] relu5 needs backward computation.
I0828 14:17:42.394737  4902 net.cpp:200] conv5 needs backward computation.
I0828 14:17:42.394747  4902 net.cpp:200] relu4 needs backward computation.
I0828 14:17:42.394757  4902 net.cpp:200] conv4 needs backward computation.
I0828 14:17:42.394769  4902 net.cpp:200] relu3 needs backward computation.
I0828 14:17:42.394779  4902 net.cpp:200] conv3 needs backward computation.
I0828 14:17:42.394791  4902 net.cpp:200] norm2 needs backward computation.
I0828 14:17:42.394809  4902 net.cpp:200] pool2 needs backward computation.
I0828 14:17:42.394820  4902 net.cpp:200] relu2 needs backward computation.
I0828 14:17:42.394830  4902 net.cpp:200] conv2 needs backward computation.
I0828 14:17:42.394841  4902 net.cpp:200] norm1 needs backward computation.
I0828 14:17:42.394853  4902 net.cpp:200] pool1 needs backward computation.
I0828 14:17:42.394865  4902 net.cpp:200] relu1 needs backward computation.
I0828 14:17:42.394875  4902 net.cpp:200] conv1 needs backward computation.
I0828 14:17:42.394886  4902 net.cpp:202] label_data_1_split does not need backward computation.
I0828 14:17:42.394897  4902 net.cpp:202] data does not need backward computation.
I0828 14:17:42.394907  4902 net.cpp:244] This network produces output accuracy
I0828 14:17:42.394918  4902 net.cpp:244] This network produces output loss
I0828 14:17:42.394948  4902 net.cpp:257] Network initialization done.
I0828 14:17:42.395110  4902 solver.cpp:56] Solver scaffolding done.
I0828 14:17:43.058120  4902 solver.cpp:331] Iteration 0, Testing net (#0)
I0828 14:17:45.661072  4902 solver.cpp:398]     Test net output #0: accuracy = 0.642
I0828 14:17:45.661160  4902 solver.cpp:398]     Test net output #1: loss = 0.661045 (* 1 = 0.661045 loss)
I0828 14:17:47.767983  4902 solver.cpp:219] Iteration 0 (0 iter/s, 4.71118s/20 iters), loss = 0.747967
I0828 14:17:47.768059  4902 solver.cpp:238]     Train net output #0: loss = 0.747967 (* 1 = 0.747967 loss)
I0828 14:17:47.768079  4902 sgd_solver.cpp:105] Iteration 0, lr = 0.001
I0828 14:18:23.819201  4902 solver.cpp:219] Iteration 20 (0.55481 iter/s, 36.0484s/20 iters), loss = 0.978517
I0828 14:18:23.819313  4902 solver.cpp:238]     Train net output #0: loss = 0.978517 (* 1 = 0.978517 loss)
I0828 14:18:23.819330  4902 sgd_solver.cpp:105] Iteration 20, lr = 0.001
I0828 14:19:00.027608  4902 solver.cpp:219] Iteration 40 (0.5524 iter/s, 36.2057s/20 iters), loss = 0.705806
I0828 14:19:00.027704  4902 solver.cpp:238]     Train net output #0: loss = 0.705806 (* 1 = 0.705806 loss)
I0828 14:19:00.027719  4902 sgd_solver.cpp:105] Iteration 40, lr = 0.001
I0828 14:19:36.063179  4902 solver.cpp:219] Iteration 60 (0.555036 iter/s, 36.0337s/20 iters), loss = 0.741668
I0828 14:19:36.063261  4902 solver.cpp:238]     Train net output #0: loss = 0.741668 (* 1 = 0.741668 loss)
I0828 14:19:36.063278  4902 sgd_solver.cpp:105] Iteration 60, lr = 0.001
I0828 14:20:12.165293  4902 solver.cpp:219] Iteration 80 (0.554037 iter/s, 36.0987s/20 iters), loss = 0.918361
I0828 14:20:12.165374  4902 solver.cpp:238]     Train net output #0: loss = 0.918361 (* 1 = 0.918361 loss)
I0828 14:20:12.165401  4902 sgd_solver.cpp:105] Iteration 80, lr = 0.001
I0828 14:20:48.379390  4902 solver.cpp:219] Iteration 100 (0.552297 iter/s, 36.2124s/20 iters), loss = 0.851281
I0828 14:20:48.379509  4902 solver.cpp:238]     Train net output #0: loss = 0.851281 (* 1 = 0.851281 loss)
I0828 14:20:48.379544  4902 sgd_solver.cpp:105] Iteration 100, lr = 0.001
I0828 14:20:57.977035  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:21:24.491453  4902 solver.cpp:219] Iteration 120 (0.553872 iter/s, 36.1094s/20 iters), loss = 0.730119
I0828 14:21:24.491557  4902 solver.cpp:238]     Train net output #0: loss = 0.730119 (* 1 = 0.730119 loss)
I0828 14:21:24.491571  4902 sgd_solver.cpp:105] Iteration 120, lr = 0.001
I0828 14:22:00.737193  4902 solver.cpp:219] Iteration 140 (0.551831 iter/s, 36.243s/20 iters), loss = 0.659267
I0828 14:22:00.737299  4902 solver.cpp:238]     Train net output #0: loss = 0.659267 (* 1 = 0.659267 loss)
I0828 14:22:00.737331  4902 sgd_solver.cpp:105] Iteration 140, lr = 0.001
I0828 14:22:37.089613  4902 solver.cpp:219] Iteration 160 (0.55021 iter/s, 36.3497s/20 iters), loss = 0.803125
I0828 14:22:37.089712  4902 solver.cpp:238]     Train net output #0: loss = 0.803125 (* 1 = 0.803125 loss)
I0828 14:22:37.089731  4902 sgd_solver.cpp:105] Iteration 160, lr = 0.001
I0828 14:23:13.348305  4902 solver.cpp:219] Iteration 180 (0.551632 iter/s, 36.256s/20 iters), loss = 0.566227
I0828 14:23:13.348404  4902 solver.cpp:238]     Train net output #0: loss = 0.566227 (* 1 = 0.566227 loss)
I0828 14:23:13.348422  4902 sgd_solver.cpp:105] Iteration 180, lr = 0.001
I0828 14:23:49.715121  4902 solver.cpp:219] Iteration 200 (0.549993 iter/s, 36.3641s/20 iters), loss = 0.667821
I0828 14:23:49.715220  4902 solver.cpp:238]     Train net output #0: loss = 0.667821 (* 1 = 0.667821 loss)
I0828 14:23:49.715240  4902 sgd_solver.cpp:105] Iteration 200, lr = 0.001
I0828 14:24:15.730664  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:24:26.003203  4902 solver.cpp:219] Iteration 220 (0.551192 iter/s, 36.285s/20 iters), loss = 0.717642
I0828 14:24:26.003298  4902 solver.cpp:238]     Train net output #0: loss = 0.717642 (* 1 = 0.717642 loss)
I0828 14:24:26.003316  4902 sgd_solver.cpp:105] Iteration 220, lr = 0.001
I0828 14:25:02.363745  4902 solver.cpp:219] Iteration 240 (0.550085 iter/s, 36.358s/20 iters), loss = 0.684592
I0828 14:25:02.363847  4902 solver.cpp:238]     Train net output #0: loss = 0.684592 (* 1 = 0.684592 loss)
I0828 14:25:02.363867  4902 sgd_solver.cpp:105] Iteration 240, lr = 0.001
I0828 14:25:17.175930  4902 solver.cpp:331] Iteration 250, Testing net (#0)
I0828 14:25:20.974840  4902 solver.cpp:398]     Test net output #0: accuracy = 0.648
I0828 14:25:20.974954  4902 solver.cpp:398]     Test net output #1: loss = 0.6265 (* 1 = 0.6265 loss)
I0828 14:25:41.055641  4902 solver.cpp:219] Iteration 260 (0.516946 iter/s, 38.6887s/20 iters), loss = 0.605832
I0828 14:25:41.055745  4902 solver.cpp:238]     Train net output #0: loss = 0.605832 (* 1 = 0.605832 loss)
I0828 14:25:41.055764  4902 sgd_solver.cpp:105] Iteration 260, lr = 0.001
I0828 14:26:17.010181  4902 solver.cpp:219] Iteration 280 (0.556329 iter/s, 35.9499s/20 iters), loss = 0.610653
I0828 14:26:17.010293  4902 solver.cpp:238]     Train net output #0: loss = 0.610653 (* 1 = 0.610653 loss)
I0828 14:26:17.010323  4902 sgd_solver.cpp:105] Iteration 280, lr = 0.001
I0828 14:26:49.014542  4902 solver.cpp:219] Iteration 300 (0.624925 iter/s, 32.0038s/20 iters), loss = 0.641758
I0828 14:26:49.014647  4902 solver.cpp:238]     Train net output #0: loss = 0.641758 (* 1 = 0.641758 loss)
I0828 14:26:49.014662  4902 sgd_solver.cpp:105] Iteration 300, lr = 0.001
I0828 14:27:24.651954  4902 solver.cpp:219] Iteration 320 (0.561236 iter/s, 35.6356s/20 iters), loss = 0.571074
I0828 14:27:24.652048  4902 solver.cpp:238]     Train net output #0: loss = 0.571074 (* 1 = 0.571074 loss)
I0828 14:27:24.652067  4902 sgd_solver.cpp:105] Iteration 320, lr = 0.001
I0828 14:27:30.859763  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:28:00.867389  4902 solver.cpp:219] Iteration 340 (0.552299 iter/s, 36.2123s/20 iters), loss = 0.587571
I0828 14:28:00.867506  4902 solver.cpp:238]     Train net output #0: loss = 0.587571 (* 1 = 0.587571 loss)
I0828 14:28:00.867524  4902 sgd_solver.cpp:105] Iteration 340, lr = 0.001
I0828 14:28:37.434710  4902 solver.cpp:219] Iteration 360 (0.546961 iter/s, 36.5657s/20 iters), loss = 0.634802
I0828 14:28:37.434818  4902 solver.cpp:238]     Train net output #0: loss = 0.634802 (* 1 = 0.634802 loss)
I0828 14:28:37.434839  4902 sgd_solver.cpp:105] Iteration 360, lr = 0.001
I0828 14:29:13.468236  4902 solver.cpp:219] Iteration 380 (0.555069 iter/s, 36.0316s/20 iters), loss = 0.593568
I0828 14:29:13.468341  4902 solver.cpp:238]     Train net output #0: loss = 0.593568 (* 1 = 0.593568 loss)
I0828 14:29:13.468360  4902 sgd_solver.cpp:105] Iteration 380, lr = 0.001
I0828 14:29:49.767447  4902 solver.cpp:219] Iteration 400 (0.550985 iter/s, 36.2986s/20 iters), loss = 0.719793
I0828 14:29:49.767565  4902 solver.cpp:238]     Train net output #0: loss = 0.719793 (* 1 = 0.719793 loss)
I0828 14:29:49.767604  4902 sgd_solver.cpp:105] Iteration 400, lr = 0.001
I0828 14:30:26.035956  4902 solver.cpp:219] Iteration 420 (0.551483 iter/s, 36.2658s/20 iters), loss = 0.588605
I0828 14:30:26.036052  4902 solver.cpp:238]     Train net output #0: loss = 0.588605 (* 1 = 0.588605 loss)
I0828 14:30:26.036077  4902 sgd_solver.cpp:105] Iteration 420, lr = 0.001
I0828 14:30:50.055515  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:31:01.901926  4902 solver.cpp:219] Iteration 440 (0.557641 iter/s, 35.8653s/20 iters), loss = 0.599512
I0828 14:31:01.902021  4902 solver.cpp:238]     Train net output #0: loss = 0.599512 (* 1 = 0.599512 loss)
I0828 14:31:01.902039  4902 sgd_solver.cpp:105] Iteration 440, lr = 0.001
I0828 14:31:38.038720  4902 solver.cpp:219] Iteration 460 (0.55348 iter/s, 36.135s/20 iters), loss = 0.514924
I0828 14:31:38.038817  4902 solver.cpp:238]     Train net output #0: loss = 0.514924 (* 1 = 0.514924 loss)
I0828 14:31:38.038835  4902 sgd_solver.cpp:105] Iteration 460, lr = 0.001
I0828 14:32:14.102432  4902 solver.cpp:219] Iteration 480 (0.554623 iter/s, 36.0605s/20 iters), loss = 0.544607
I0828 14:32:14.102525  4902 solver.cpp:238]     Train net output #0: loss = 0.544607 (* 1 = 0.544607 loss)
I0828 14:32:14.102543  4902 sgd_solver.cpp:105] Iteration 480, lr = 0.001
I0828 14:32:47.169977  4902 solver.cpp:331] Iteration 500, Testing net (#0)
I0828 14:32:50.910284  4902 solver.cpp:398]     Test net output #0: accuracy = 0.689
I0828 14:32:50.910362  4902 solver.cpp:398]     Test net output #1: loss = 0.538544 (* 1 = 0.538544 loss)
I0828 14:32:52.621693  4902 solver.cpp:219] Iteration 500 (0.519247 iter/s, 38.5173s/20 iters), loss = 0.552549
I0828 14:32:52.621783  4902 solver.cpp:238]     Train net output #0: loss = 0.552549 (* 1 = 0.552549 loss)
I0828 14:32:52.621801  4902 sgd_solver.cpp:105] Iteration 500, lr = 0.001
I0828 14:33:28.034086  4902 solver.cpp:219] Iteration 520 (0.564819 iter/s, 35.4096s/20 iters), loss = 0.539371
I0828 14:33:28.034195  4902 solver.cpp:238]     Train net output #0: loss = 0.539371 (* 1 = 0.539371 loss)
I0828 14:33:28.034217  4902 sgd_solver.cpp:105] Iteration 520, lr = 0.001
I0828 14:34:04.291016  4902 solver.cpp:219] Iteration 540 (0.551659 iter/s, 36.2543s/20 iters), loss = 0.561899
I0828 14:34:04.291119  4902 solver.cpp:238]     Train net output #0: loss = 0.561899 (* 1 = 0.561899 loss)
I0828 14:34:04.291137  4902 sgd_solver.cpp:105] Iteration 540, lr = 0.001
I0828 14:34:08.451740  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:34:40.441581  4902 solver.cpp:219] Iteration 560 (0.553266 iter/s, 36.149s/20 iters), loss = 0.552101
I0828 14:34:40.441682  4902 solver.cpp:238]     Train net output #0: loss = 0.552101 (* 1 = 0.552101 loss)
I0828 14:34:40.441712  4902 sgd_solver.cpp:105] Iteration 560, lr = 0.001
I0828 14:35:16.279362  4902 solver.cpp:219] Iteration 580 (0.558114 iter/s, 35.835s/20 iters), loss = 0.53098
I0828 14:35:16.279445  4902 solver.cpp:238]     Train net output #0: loss = 0.53098 (* 1 = 0.53098 loss)
I0828 14:35:16.279462  4902 sgd_solver.cpp:105] Iteration 580, lr = 0.001
I0828 14:35:52.466178  4902 solver.cpp:219] Iteration 600 (0.552714 iter/s, 36.1851s/20 iters), loss = 0.539767
I0828 14:35:52.466286  4902 solver.cpp:238]     Train net output #0: loss = 0.539767 (* 1 = 0.539767 loss)
I0828 14:35:52.466305  4902 sgd_solver.cpp:105] Iteration 600, lr = 0.001
I0828 14:36:28.636821  4902 solver.cpp:219] Iteration 620 (0.552975 iter/s, 36.168s/20 iters), loss = 0.505699
I0828 14:36:28.636914  4902 solver.cpp:238]     Train net output #0: loss = 0.505699 (* 1 = 0.505699 loss)
I0828 14:36:28.636934  4902 sgd_solver.cpp:105] Iteration 620, lr = 0.001
I0828 14:37:04.915271  4902 solver.cpp:219] Iteration 640 (0.55134 iter/s, 36.2753s/20 iters), loss = 0.559947
I0828 14:37:04.915359  4902 solver.cpp:238]     Train net output #0: loss = 0.559947 (* 1 = 0.559947 loss)
I0828 14:37:04.915375  4902 sgd_solver.cpp:105] Iteration 640, lr = 0.001
I0828 14:37:25.355723  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:37:41.178298  4902 solver.cpp:219] Iteration 660 (0.551566 iter/s, 36.2604s/20 iters), loss = 0.531143
I0828 14:37:41.178396  4902 solver.cpp:238]     Train net output #0: loss = 0.531143 (* 1 = 0.531143 loss)
I0828 14:37:41.178414  4902 sgd_solver.cpp:105] Iteration 660, lr = 0.001
I0828 14:38:17.353183  4902 solver.cpp:219] Iteration 680 (0.552918 iter/s, 36.1717s/20 iters), loss = 0.50016
I0828 14:38:17.353294  4902 solver.cpp:238]     Train net output #0: loss = 0.50016 (* 1 = 0.50016 loss)
I0828 14:38:17.353310  4902 sgd_solver.cpp:105] Iteration 680, lr = 0.001
I0828 14:38:53.433001  4902 solver.cpp:219] Iteration 700 (0.55437 iter/s, 36.077s/20 iters), loss = 0.521471
I0828 14:38:53.433110  4902 solver.cpp:238]     Train net output #0: loss = 0.521471 (* 1 = 0.521471 loss)
I0828 14:38:53.433145  4902 sgd_solver.cpp:105] Iteration 700, lr = 0.001
I0828 14:39:29.488389  4902 solver.cpp:219] Iteration 720 (0.554732 iter/s, 36.0534s/20 iters), loss = 0.588418
I0828 14:39:29.488490  4902 solver.cpp:238]     Train net output #0: loss = 0.588418 (* 1 = 0.588418 loss)
I0828 14:39:29.488508  4902 sgd_solver.cpp:105] Iteration 720, lr = 0.001
I0828 14:40:05.828757  4902 solver.cpp:219] Iteration 740 (0.550361 iter/s, 36.3398s/20 iters), loss = 0.536536
I0828 14:40:05.828853  4902 solver.cpp:238]     Train net output #0: loss = 0.536536 (* 1 = 0.536536 loss)
I0828 14:40:05.828871  4902 sgd_solver.cpp:105] Iteration 740, lr = 0.001
I0828 14:40:21.056392  4902 solver.cpp:331] Iteration 750, Testing net (#0)
I0828 14:40:24.758241  4902 solver.cpp:398]     Test net output #0: accuracy = 0.697
I0828 14:40:24.758333  4902 solver.cpp:398]     Test net output #1: loss = 0.567209 (* 1 = 0.567209 loss)
I0828 14:40:44.819088  4902 solver.cpp:219] Iteration 760 (0.512984 iter/s, 38.9876s/20 iters), loss = 0.518278
I0828 14:40:44.819188  4902 solver.cpp:238]     Train net output #0: loss = 0.518278 (* 1 = 0.518278 loss)
I0828 14:40:44.819207  4902 sgd_solver.cpp:105] Iteration 760, lr = 0.001
I0828 14:40:45.410259  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:41:20.734113  4902 solver.cpp:219] Iteration 780 (0.556898 iter/s, 35.9132s/20 iters), loss = 0.530689
I0828 14:41:20.734210  4902 solver.cpp:238]     Train net output #0: loss = 0.530689 (* 1 = 0.530689 loss)
I0828 14:41:20.734227  4902 sgd_solver.cpp:105] Iteration 780, lr = 0.001
I0828 14:41:56.698045  4902 solver.cpp:219] Iteration 800 (0.556128 iter/s, 35.963s/20 iters), loss = 0.497461
I0828 14:41:56.698137  4902 solver.cpp:238]     Train net output #0: loss = 0.497461 (* 1 = 0.497461 loss)
I0828 14:41:56.698153  4902 sgd_solver.cpp:105] Iteration 800, lr = 0.001
I0828 14:42:32.893185  4902 solver.cpp:219] Iteration 820 (0.552602 iter/s, 36.1924s/20 iters), loss = 0.56262
I0828 14:42:32.893295  4902 solver.cpp:238]     Train net output #0: loss = 0.56262 (* 1 = 0.56262 loss)
I0828 14:42:32.893312  4902 sgd_solver.cpp:105] Iteration 820, lr = 0.001
I0828 14:43:08.961789  4902 solver.cpp:219] Iteration 840 (0.554548 iter/s, 36.0654s/20 iters), loss = 0.449814
I0828 14:43:08.961877  4902 solver.cpp:238]     Train net output #0: loss = 0.449814 (* 1 = 0.449814 loss)
I0828 14:43:08.961894  4902 sgd_solver.cpp:105] Iteration 840, lr = 0.001
I0828 14:43:45.460677  4902 solver.cpp:219] Iteration 860 (0.548004 iter/s, 36.4961s/20 iters), loss = 0.470083
I0828 14:43:45.460777  4902 solver.cpp:238]     Train net output #0: loss = 0.470083 (* 1 = 0.470083 loss)
I0828 14:43:45.460793  4902 sgd_solver.cpp:105] Iteration 860, lr = 0.001
I0828 14:44:04.108592  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:44:21.673503  4902 solver.cpp:219] Iteration 880 (0.552323 iter/s, 36.2107s/20 iters), loss = 0.472396
I0828 14:44:21.673602  4902 solver.cpp:238]     Train net output #0: loss = 0.472396 (* 1 = 0.472396 loss)
I0828 14:44:21.673619  4902 sgd_solver.cpp:105] Iteration 880, lr = 0.001
I0828 14:44:57.901999  4902 solver.cpp:219] Iteration 900 (0.552061 iter/s, 36.2279s/20 iters), loss = 0.468375
I0828 14:44:57.902103  4902 solver.cpp:238]     Train net output #0: loss = 0.468375 (* 1 = 0.468375 loss)
I0828 14:44:57.902129  4902 sgd_solver.cpp:105] Iteration 900, lr = 0.001
I0828 14:45:33.996763  4902 solver.cpp:219] Iteration 920 (0.554155 iter/s, 36.091s/20 iters), loss = 0.535355
I0828 14:45:33.996846  4902 solver.cpp:238]     Train net output #0: loss = 0.535355 (* 1 = 0.535355 loss)
I0828 14:45:33.996865  4902 sgd_solver.cpp:105] Iteration 920, lr = 0.001
I0828 14:46:10.051726  4902 solver.cpp:219] Iteration 940 (0.55475 iter/s, 36.0523s/20 iters), loss = 0.509053
I0828 14:46:10.051818  4902 solver.cpp:238]     Train net output #0: loss = 0.509053 (* 1 = 0.509053 loss)
I0828 14:46:10.051838  4902 sgd_solver.cpp:105] Iteration 940, lr = 0.001
I0828 14:46:46.435725  4902 solver.cpp:219] Iteration 960 (0.549725 iter/s, 36.3818s/20 iters), loss = 0.449888
I0828 14:46:46.435816  4902 solver.cpp:238]     Train net output #0: loss = 0.449888 (* 1 = 0.449888 loss)
I0828 14:46:46.435832  4902 sgd_solver.cpp:105] Iteration 960, lr = 0.001
I0828 14:47:21.298957  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:47:22.430191  4902 solver.cpp:219] Iteration 980 (0.55569 iter/s, 35.9913s/20 iters), loss = 0.414596
I0828 14:47:22.430304  4902 solver.cpp:238]     Train net output #0: loss = 0.414596 (* 1 = 0.414596 loss)
I0828 14:47:22.430336  4902 sgd_solver.cpp:105] Iteration 980, lr = 0.001
I0828 14:47:55.468314  4902 solver.cpp:331] Iteration 1000, Testing net (#0)
I0828 14:47:59.251971  4902 solver.cpp:398]     Test net output #0: accuracy = 0.827
I0828 14:47:59.252063  4902 solver.cpp:398]     Test net output #1: loss = 0.408909 (* 1 = 0.408909 loss)
I0828 14:48:01.068641  4902 solver.cpp:219] Iteration 1000 (0.517653 iter/s, 38.6359s/20 iters), loss = 0.454997
I0828 14:48:01.068768  4902 solver.cpp:238]     Train net output #0: loss = 0.454997 (* 1 = 0.454997 loss)
I0828 14:48:01.068804  4902 sgd_solver.cpp:105] Iteration 1000, lr = 0.001
I0828 14:48:37.307476  4902 solver.cpp:219] Iteration 1020 (0.551903 iter/s, 36.2382s/20 iters), loss = 0.401882
I0828 14:48:37.307580  4902 solver.cpp:238]     Train net output #0: loss = 0.401882 (* 1 = 0.401882 loss)
I0828 14:48:37.307611  4902 sgd_solver.cpp:105] Iteration 1020, lr = 0.001
I0828 14:49:13.476495  4902 solver.cpp:219] Iteration 1040 (0.552986 iter/s, 36.1673s/20 iters), loss = 0.400674
I0828 14:49:13.476598  4902 solver.cpp:238]     Train net output #0: loss = 0.400674 (* 1 = 0.400674 loss)
I0828 14:49:13.476629  4902 sgd_solver.cpp:105] Iteration 1040, lr = 0.001
I0828 14:49:49.745841  4902 solver.cpp:219] Iteration 1060 (0.551458 iter/s, 36.2675s/20 iters), loss = 0.38143
I0828 14:49:49.745952  4902 solver.cpp:238]     Train net output #0: loss = 0.38143 (* 1 = 0.38143 loss)
I0828 14:49:49.745986  4902 sgd_solver.cpp:105] Iteration 1060, lr = 0.001
I0828 14:50:25.968461  4902 solver.cpp:219] Iteration 1080 (0.552184 iter/s, 36.2198s/20 iters), loss = 0.412336
I0828 14:50:25.968571  4902 solver.cpp:238]     Train net output #0: loss = 0.412336 (* 1 = 0.412336 loss)
I0828 14:50:25.968588  4902 sgd_solver.cpp:105] Iteration 1080, lr = 0.001
I0828 14:50:40.988008  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:51:01.905844  4902 solver.cpp:219] Iteration 1100 (0.556567 iter/s, 35.9346s/20 iters), loss = 0.397184
I0828 14:51:01.905937  4902 solver.cpp:238]     Train net output #0: loss = 0.397184 (* 1 = 0.397184 loss)
I0828 14:51:01.905958  4902 sgd_solver.cpp:105] Iteration 1100, lr = 0.001
I0828 14:51:38.245260  4902 solver.cpp:219] Iteration 1120 (0.550415 iter/s, 36.3362s/20 iters), loss = 0.373598
I0828 14:51:38.245357  4902 solver.cpp:238]     Train net output #0: loss = 0.373598 (* 1 = 0.373598 loss)
I0828 14:51:38.245380  4902 sgd_solver.cpp:105] Iteration 1120, lr = 0.001
I0828 14:52:14.409325  4902 solver.cpp:219] Iteration 1140 (0.553069 iter/s, 36.1618s/20 iters), loss = 0.348395
I0828 14:52:14.409431  4902 solver.cpp:238]     Train net output #0: loss = 0.348395 (* 1 = 0.348395 loss)
I0828 14:52:14.409452  4902 sgd_solver.cpp:105] Iteration 1140, lr = 0.001
I0828 14:52:50.602882  4902 solver.cpp:219] Iteration 1160 (0.552626 iter/s, 36.1909s/20 iters), loss = 0.351443
I0828 14:52:50.603005  4902 solver.cpp:238]     Train net output #0: loss = 0.351443 (* 1 = 0.351443 loss)
I0828 14:52:50.603039  4902 sgd_solver.cpp:105] Iteration 1160, lr = 0.001
I0828 14:53:26.763654  4902 solver.cpp:219] Iteration 1180 (0.553134 iter/s, 36.1576s/20 iters), loss = 0.356342
I0828 14:53:26.763756  4902 solver.cpp:238]     Train net output #0: loss = 0.356342 (* 1 = 0.356342 loss)
I0828 14:53:26.763775  4902 sgd_solver.cpp:105] Iteration 1180, lr = 0.001
I0828 14:53:59.931771  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:54:03.017746  4902 solver.cpp:219] Iteration 1200 (0.55171 iter/s, 36.2509s/20 iters), loss = 0.353724
I0828 14:54:03.017843  4902 solver.cpp:238]     Train net output #0: loss = 0.353724 (* 1 = 0.353724 loss)
I0828 14:54:03.017882  4902 sgd_solver.cpp:105] Iteration 1200, lr = 0.001
I0828 14:54:39.060922  4902 solver.cpp:219] Iteration 1220 (0.554932 iter/s, 36.0404s/20 iters), loss = 0.381731
I0828 14:54:39.061053  4902 solver.cpp:238]     Train net output #0: loss = 0.381731 (* 1 = 0.381731 loss)
I0828 14:54:39.061086  4902 sgd_solver.cpp:105] Iteration 1220, lr = 0.001
I0828 14:55:15.210449  4902 solver.cpp:219] Iteration 1240 (0.553299 iter/s, 36.1468s/20 iters), loss = 0.348799
I0828 14:55:15.210575  4902 solver.cpp:238]     Train net output #0: loss = 0.348799 (* 1 = 0.348799 loss)
I0828 14:55:15.210608  4902 sgd_solver.cpp:105] Iteration 1240, lr = 0.001
I0828 14:55:30.249013  4902 solver.cpp:331] Iteration 1250, Testing net (#0)
I0828 14:55:32.573446  4960 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:55:33.531119  4902 blocking_queue.cpp:49] Waiting for data
I0828 14:55:34.101204  4902 solver.cpp:398]     Test net output #0: accuracy = 0.823
I0828 14:55:34.101295  4902 solver.cpp:398]     Test net output #1: loss = 0.354047 (* 1 = 0.354047 loss)
I0828 14:55:53.935077  4902 solver.cpp:219] Iteration 1260 (0.516489 iter/s, 38.723s/20 iters), loss = 0.344162
I0828 14:55:53.935185  4902 solver.cpp:238]     Train net output #0: loss = 0.344162 (* 1 = 0.344162 loss)
I0828 14:55:53.935217  4902 sgd_solver.cpp:105] Iteration 1260, lr = 0.001
I0828 14:56:30.327452  4902 solver.cpp:219] Iteration 1280 (0.54959 iter/s, 36.3908s/20 iters), loss = 0.324805
I0828 14:56:30.327569  4902 solver.cpp:238]     Train net output #0: loss = 0.324805 (* 1 = 0.324805 loss)
I0828 14:56:30.327602  4902 sgd_solver.cpp:105] Iteration 1280, lr = 0.001
I0828 14:57:06.449380  4902 solver.cpp:219] Iteration 1300 (0.553705 iter/s, 36.1203s/20 iters), loss = 0.358935
I0828 14:57:06.449492  4902 solver.cpp:238]     Train net output #0: loss = 0.358935 (* 1 = 0.358935 loss)
I0828 14:57:06.449535  4902 sgd_solver.cpp:105] Iteration 1300, lr = 0.001
I0828 14:57:19.640771  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 14:57:42.659493  4902 solver.cpp:219] Iteration 1320 (0.55238 iter/s, 36.2069s/20 iters), loss = 0.321129
I0828 14:57:42.659607  4902 solver.cpp:238]     Train net output #0: loss = 0.321129 (* 1 = 0.321129 loss)
I0828 14:57:42.659644  4902 sgd_solver.cpp:105] Iteration 1320, lr = 0.001
I0828 14:58:18.756954  4902 solver.cpp:219] Iteration 1340 (0.554104 iter/s, 36.0943s/20 iters), loss = 0.399287
I0828 14:58:18.757057  4902 solver.cpp:238]     Train net output #0: loss = 0.399287 (* 1 = 0.399287 loss)
I0828 14:58:18.757076  4902 sgd_solver.cpp:105] Iteration 1340, lr = 0.001
I0828 14:58:54.928104  4902 solver.cpp:219] Iteration 1360 (0.552997 iter/s, 36.1665s/20 iters), loss = 0.302078
I0828 14:58:54.928215  4902 solver.cpp:238]     Train net output #0: loss = 0.302078 (* 1 = 0.302078 loss)
I0828 14:58:54.928233  4902 sgd_solver.cpp:105] Iteration 1360, lr = 0.001
I0828 14:59:30.351732  4902 solver.cpp:219] Iteration 1380 (0.564693 iter/s, 35.4175s/20 iters), loss = 0.350926
I0828 14:59:30.351836  4902 solver.cpp:238]     Train net output #0: loss = 0.350926 (* 1 = 0.350926 loss)
I0828 14:59:30.351855  4902 sgd_solver.cpp:105] Iteration 1380, lr = 0.001
I0828 15:00:06.371673  4902 solver.cpp:219] Iteration 1400 (0.55529 iter/s, 36.0172s/20 iters), loss = 0.384702
I0828 15:00:06.371786  4902 solver.cpp:238]     Train net output #0: loss = 0.384702 (* 1 = 0.384702 loss)
I0828 15:00:06.371820  4902 sgd_solver.cpp:105] Iteration 1400, lr = 0.001
I0828 15:00:35.954131  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:00:42.414700  4902 solver.cpp:219] Iteration 1420 (0.554923 iter/s, 36.0411s/20 iters), loss = 0.344617
I0828 15:00:42.414819  4902 solver.cpp:238]     Train net output #0: loss = 0.344617 (* 1 = 0.344617 loss)
I0828 15:00:42.414855  4902 sgd_solver.cpp:105] Iteration 1420, lr = 0.001
I0828 15:01:18.625147  4902 solver.cpp:219] Iteration 1440 (0.552336 iter/s, 36.2098s/20 iters), loss = 0.366002
I0828 15:01:18.625257  4902 solver.cpp:238]     Train net output #0: loss = 0.366002 (* 1 = 0.366002 loss)
I0828 15:01:18.625275  4902 sgd_solver.cpp:105] Iteration 1440, lr = 0.001
I0828 15:01:54.654785  4902 solver.cpp:219] Iteration 1460 (0.555159 iter/s, 36.0257s/20 iters), loss = 0.255495
I0828 15:01:54.654886  4902 solver.cpp:238]     Train net output #0: loss = 0.255495 (* 1 = 0.255495 loss)
I0828 15:01:54.654904  4902 sgd_solver.cpp:105] Iteration 1460, lr = 0.001
I0828 15:02:26.503001  4902 solver.cpp:219] Iteration 1480 (0.628032 iter/s, 31.8455s/20 iters), loss = 0.296272
I0828 15:02:26.503111  4902 solver.cpp:238]     Train net output #0: loss = 0.296272 (* 1 = 0.296272 loss)
I0828 15:02:26.503130  4902 sgd_solver.cpp:105] Iteration 1480, lr = 0.001
I0828 15:02:59.618779  4902 solver.cpp:331] Iteration 1500, Testing net (#0)
I0828 15:03:03.312741  4902 solver.cpp:398]     Test net output #0: accuracy = 0.871
I0828 15:03:03.312841  4902 solver.cpp:398]     Test net output #1: loss = 0.282184 (* 1 = 0.282184 loss)
I0828 15:03:05.086994  4902 solver.cpp:219] Iteration 1500 (0.518373 iter/s, 38.5823s/20 iters), loss = 0.214105
I0828 15:03:05.087087  4902 solver.cpp:238]     Train net output #0: loss = 0.214105 (* 1 = 0.214105 loss)
I0828 15:03:05.087105  4902 sgd_solver.cpp:105] Iteration 1500, lr = 0.0001
I0828 15:03:41.352977  4902 solver.cpp:219] Iteration 1520 (0.551529 iter/s, 36.2628s/20 iters), loss = 0.26828
I0828 15:03:41.353080  4902 solver.cpp:238]     Train net output #0: loss = 0.26828 (* 1 = 0.26828 loss)
I0828 15:03:41.353114  4902 sgd_solver.cpp:105] Iteration 1520, lr = 0.0001
I0828 15:03:51.092293  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:04:17.544921  4902 solver.cpp:219] Iteration 1540 (0.552643 iter/s, 36.1898s/20 iters), loss = 0.24899
I0828 15:04:17.545032  4902 solver.cpp:238]     Train net output #0: loss = 0.24899 (* 1 = 0.24899 loss)
I0828 15:04:17.545065  4902 sgd_solver.cpp:105] Iteration 1540, lr = 0.0001
I0828 15:04:53.836748  4902 solver.cpp:219] Iteration 1560 (0.551114 iter/s, 36.2902s/20 iters), loss = 0.215987
I0828 15:04:53.836840  4902 solver.cpp:238]     Train net output #0: loss = 0.215987 (* 1 = 0.215987 loss)
I0828 15:04:53.836859  4902 sgd_solver.cpp:105] Iteration 1560, lr = 0.0001
I0828 15:05:30.057601  4902 solver.cpp:219] Iteration 1580 (0.552193 iter/s, 36.2192s/20 iters), loss = 0.270035
I0828 15:05:30.057709  4902 solver.cpp:238]     Train net output #0: loss = 0.270035 (* 1 = 0.270035 loss)
I0828 15:05:30.057730  4902 sgd_solver.cpp:105] Iteration 1580, lr = 0.0001
I0828 15:06:06.350360  4902 solver.cpp:219] Iteration 1600 (0.551117 iter/s, 36.2899s/20 iters), loss = 0.280471
I0828 15:06:06.350459  4902 solver.cpp:238]     Train net output #0: loss = 0.280471 (* 1 = 0.280471 loss)
I0828 15:06:06.350487  4902 sgd_solver.cpp:105] Iteration 1600, lr = 0.0001
I0828 15:06:42.528573  4902 solver.cpp:219] Iteration 1620 (0.552845 iter/s, 36.1765s/20 iters), loss = 0.25364
I0828 15:06:42.528695  4902 solver.cpp:238]     Train net output #0: loss = 0.25364 (* 1 = 0.25364 loss)
I0828 15:06:42.528728  4902 sgd_solver.cpp:105] Iteration 1620, lr = 0.0001
I0828 15:07:10.328807  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:07:18.871520  4902 solver.cpp:219] Iteration 1640 (0.550411 iter/s, 36.3365s/20 iters), loss = 0.207537
I0828 15:07:18.871630  4902 solver.cpp:238]     Train net output #0: loss = 0.207537 (* 1 = 0.207537 loss)
I0828 15:07:18.871661  4902 sgd_solver.cpp:105] Iteration 1640, lr = 0.0001
I0828 15:07:53.472513  4902 solver.cpp:219] Iteration 1660 (0.578063 iter/s, 34.5983s/20 iters), loss = 0.252819
I0828 15:07:53.472625  4902 solver.cpp:238]     Train net output #0: loss = 0.252819 (* 1 = 0.252819 loss)
I0828 15:07:53.472656  4902 sgd_solver.cpp:105] Iteration 1660, lr = 0.0001
I0828 15:08:29.658906  4902 solver.cpp:219] Iteration 1680 (0.552742 iter/s, 36.1832s/20 iters), loss = 0.293244
I0828 15:08:29.659024  4902 solver.cpp:238]     Train net output #0: loss = 0.293244 (* 1 = 0.293244 loss)
I0828 15:08:29.659044  4902 sgd_solver.cpp:105] Iteration 1680, lr = 0.0001
I0828 15:09:05.727007  4902 solver.cpp:219] Iteration 1700 (0.554555 iter/s, 36.065s/20 iters), loss = 0.304601
I0828 15:09:05.727093  4902 solver.cpp:238]     Train net output #0: loss = 0.304601 (* 1 = 0.304601 loss)
I0828 15:09:05.727110  4902 sgd_solver.cpp:105] Iteration 1700, lr = 0.0001
I0828 15:09:41.658638  4902 solver.cpp:219] Iteration 1720 (0.556656 iter/s, 35.9288s/20 iters), loss = 0.304484
I0828 15:09:41.658727  4902 solver.cpp:238]     Train net output #0: loss = 0.304484 (* 1 = 0.304484 loss)
I0828 15:09:41.658746  4902 sgd_solver.cpp:105] Iteration 1720, lr = 0.0001
I0828 15:10:17.958268  4902 solver.cpp:219] Iteration 1740 (0.551018 iter/s, 36.2964s/20 iters), loss = 0.216521
I0828 15:10:17.958372  4902 solver.cpp:238]     Train net output #0: loss = 0.216521 (* 1 = 0.216521 loss)
I0828 15:10:17.958391  4902 sgd_solver.cpp:105] Iteration 1740, lr = 0.0001
I0828 15:10:25.760862  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:10:32.908725  4902 solver.cpp:331] Iteration 1750, Testing net (#0)
I0828 15:10:36.725821  4902 solver.cpp:398]     Test net output #0: accuracy = 0.889
I0828 15:10:36.725896  4902 solver.cpp:398]     Test net output #1: loss = 0.247972 (* 1 = 0.247972 loss)
I0828 15:10:56.582844  4902 solver.cpp:219] Iteration 1760 (0.517927 iter/s, 38.6155s/20 iters), loss = 0.240112
I0828 15:10:56.582945  4902 solver.cpp:238]     Train net output #0: loss = 0.240112 (* 1 = 0.240112 loss)
I0828 15:10:56.582962  4902 sgd_solver.cpp:105] Iteration 1760, lr = 0.0001
I0828 15:11:32.717407  4902 solver.cpp:219] Iteration 1780 (0.55353 iter/s, 36.1317s/20 iters), loss = 0.267483
I0828 15:11:32.717514  4902 solver.cpp:238]     Train net output #0: loss = 0.267483 (* 1 = 0.267483 loss)
I0828 15:11:32.717535  4902 sgd_solver.cpp:105] Iteration 1780, lr = 0.0001
I0828 15:12:08.957816  4902 solver.cpp:219] Iteration 1800 (0.551894 iter/s, 36.2388s/20 iters), loss = 0.202753
I0828 15:12:08.957906  4902 solver.cpp:238]     Train net output #0: loss = 0.202753 (* 1 = 0.202753 loss)
I0828 15:12:08.957923  4902 sgd_solver.cpp:105] Iteration 1800, lr = 0.0001
I0828 15:12:45.154604  4902 solver.cpp:219] Iteration 1820 (0.552576 iter/s, 36.1941s/20 iters), loss = 0.302328
I0828 15:12:45.154692  4902 solver.cpp:238]     Train net output #0: loss = 0.302328 (* 1 = 0.302328 loss)
I0828 15:12:45.154708  4902 sgd_solver.cpp:105] Iteration 1820, lr = 0.0001
I0828 15:13:21.206940  4902 solver.cpp:219] Iteration 1840 (0.554791 iter/s, 36.0496s/20 iters), loss = 0.268839
I0828 15:13:21.207048  4902 solver.cpp:238]     Train net output #0: loss = 0.268839 (* 1 = 0.268839 loss)
I0828 15:13:21.207079  4902 sgd_solver.cpp:105] Iteration 1840, lr = 0.0001
I0828 15:13:45.470376  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:13:57.393110  4902 solver.cpp:219] Iteration 1860 (0.552738 iter/s, 36.1835s/20 iters), loss = 0.278624
I0828 15:13:57.393225  4902 solver.cpp:238]     Train net output #0: loss = 0.278624 (* 1 = 0.278624 loss)
I0828 15:13:57.393255  4902 sgd_solver.cpp:105] Iteration 1860, lr = 0.0001
I0828 15:14:33.492372  4902 solver.cpp:219] Iteration 1880 (0.554123 iter/s, 36.0931s/20 iters), loss = 0.229767
I0828 15:14:33.492476  4902 solver.cpp:238]     Train net output #0: loss = 0.229767 (* 1 = 0.229767 loss)
I0828 15:14:33.492494  4902 sgd_solver.cpp:105] Iteration 1880, lr = 0.0001
I0828 15:15:09.623304  4902 solver.cpp:219] Iteration 1900 (0.553551 iter/s, 36.1303s/20 iters), loss = 0.260863
I0828 15:15:09.623406  4902 solver.cpp:238]     Train net output #0: loss = 0.260863 (* 1 = 0.260863 loss)
I0828 15:15:09.623423  4902 sgd_solver.cpp:105] Iteration 1900, lr = 0.0001
I0828 15:15:45.626847  4902 solver.cpp:219] Iteration 1920 (0.555542 iter/s, 36.0009s/20 iters), loss = 0.208643
I0828 15:15:45.626967  4902 solver.cpp:238]     Train net output #0: loss = 0.208643 (* 1 = 0.208643 loss)
I0828 15:15:45.626998  4902 sgd_solver.cpp:105] Iteration 1920, lr = 0.0001
I0828 15:16:21.605274  4902 solver.cpp:219] Iteration 1940 (0.555913 iter/s, 35.9768s/20 iters), loss = 0.206539
I0828 15:16:21.605389  4902 solver.cpp:238]     Train net output #0: loss = 0.206539 (* 1 = 0.206539 loss)
I0828 15:16:21.605422  4902 sgd_solver.cpp:105] Iteration 1940, lr = 0.0001
I0828 15:16:57.859307  4902 solver.cpp:219] Iteration 1960 (0.551705 iter/s, 36.2512s/20 iters), loss = 0.232031
I0828 15:16:57.859422  4902 solver.cpp:238]     Train net output #0: loss = 0.232031 (* 1 = 0.232031 loss)
I0828 15:16:57.859452  4902 sgd_solver.cpp:105] Iteration 1960, lr = 0.0001
I0828 15:17:03.776062  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:17:34.035856  4902 solver.cpp:219] Iteration 1980 (0.552939 iter/s, 36.1703s/20 iters), loss = 0.235818
I0828 15:17:34.035944  4902 solver.cpp:238]     Train net output #0: loss = 0.235818 (* 1 = 0.235818 loss)
I0828 15:17:34.035960  4902 sgd_solver.cpp:105] Iteration 1980, lr = 0.0001
I0828 15:18:07.154134  4902 solver.cpp:331] Iteration 2000, Testing net (#0)
I0828 15:18:10.880604  4902 solver.cpp:398]     Test net output #0: accuracy = 0.897
I0828 15:18:10.880704  4902 solver.cpp:398]     Test net output #1: loss = 0.254721 (* 1 = 0.254721 loss)
I0828 15:18:12.729128  4902 solver.cpp:219] Iteration 2000 (0.516919 iter/s, 38.6908s/20 iters), loss = 0.246829
I0828 15:18:12.729243  4902 solver.cpp:238]     Train net output #0: loss = 0.246829 (* 1 = 0.246829 loss)
I0828 15:18:12.729275  4902 sgd_solver.cpp:105] Iteration 2000, lr = 0.0001
I0828 15:18:49.133170  4902 solver.cpp:219] Iteration 2020 (0.54945 iter/s, 36.4001s/20 iters), loss = 0.206098
I0828 15:18:49.133283  4902 solver.cpp:238]     Train net output #0: loss = 0.206098 (* 1 = 0.206098 loss)
I0828 15:18:49.133317  4902 sgd_solver.cpp:105] Iteration 2020, lr = 0.0001
I0828 15:19:25.284363  4902 solver.cpp:219] Iteration 2040 (0.553273 iter/s, 36.1485s/20 iters), loss = 0.276629
I0828 15:19:25.284463  4902 solver.cpp:238]     Train net output #0: loss = 0.276629 (* 1 = 0.276629 loss)
I0828 15:19:25.284478  4902 sgd_solver.cpp:105] Iteration 2040, lr = 0.0001
I0828 15:20:01.434307  4902 solver.cpp:219] Iteration 2060 (0.553266 iter/s, 36.149s/20 iters), loss = 0.212162
I0828 15:20:01.434408  4902 solver.cpp:238]     Train net output #0: loss = 0.212162 (* 1 = 0.212162 loss)
I0828 15:20:01.434425  4902 sgd_solver.cpp:105] Iteration 2060, lr = 0.0001
I0828 15:20:23.830464  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:20:37.656716  4902 solver.cpp:219] Iteration 2080 (0.552171 iter/s, 36.2207s/20 iters), loss = 0.201355
I0828 15:20:37.656811  4902 solver.cpp:238]     Train net output #0: loss = 0.201355 (* 1 = 0.201355 loss)
I0828 15:20:37.656827  4902 sgd_solver.cpp:105] Iteration 2080, lr = 0.0001
I0828 15:21:13.685664  4902 solver.cpp:219] Iteration 2100 (0.555151 iter/s, 36.0262s/20 iters), loss = 0.184578
I0828 15:21:13.685770  4902 solver.cpp:238]     Train net output #0: loss = 0.184578 (* 1 = 0.184578 loss)
I0828 15:21:13.685787  4902 sgd_solver.cpp:105] Iteration 2100, lr = 0.0001
I0828 15:21:50.090332  4902 solver.cpp:219] Iteration 2120 (0.549423 iter/s, 36.4018s/20 iters), loss = 0.147063
I0828 15:21:50.090415  4902 solver.cpp:238]     Train net output #0: loss = 0.147063 (* 1 = 0.147063 loss)
I0828 15:21:50.090431  4902 sgd_solver.cpp:105] Iteration 2120, lr = 0.0001
I0828 15:22:26.219352  4902 solver.cpp:219] Iteration 2140 (0.553601 iter/s, 36.1271s/20 iters), loss = 0.259982
I0828 15:22:26.219439  4902 solver.cpp:238]     Train net output #0: loss = 0.259982 (* 1 = 0.259982 loss)
I0828 15:22:26.219456  4902 sgd_solver.cpp:105] Iteration 2140, lr = 0.0001
I0828 15:23:02.565606  4902 solver.cpp:219] Iteration 2160 (0.550311 iter/s, 36.3431s/20 iters), loss = 0.19865
I0828 15:23:02.565707  4902 solver.cpp:238]     Train net output #0: loss = 0.19865 (* 1 = 0.19865 loss)
I0828 15:23:02.565726  4902 sgd_solver.cpp:105] Iteration 2160, lr = 0.0001
I0828 15:23:38.720070  4902 solver.cpp:219] Iteration 2180 (0.553226 iter/s, 36.1516s/20 iters), loss = 0.269533
I0828 15:23:38.720168  4902 solver.cpp:238]     Train net output #0: loss = 0.269533 (* 1 = 0.269533 loss)
I0828 15:23:38.720185  4902 sgd_solver.cpp:105] Iteration 2180, lr = 0.0001
I0828 15:23:41.257244  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:24:14.819391  4902 solver.cpp:219] Iteration 2200 (0.554069 iter/s, 36.0966s/20 iters), loss = 0.15366
I0828 15:24:14.819485  4902 solver.cpp:238]     Train net output #0: loss = 0.15366 (* 1 = 0.15366 loss)
I0828 15:24:14.819504  4902 sgd_solver.cpp:105] Iteration 2200, lr = 0.0001
I0828 15:24:51.095099  4902 solver.cpp:219] Iteration 2220 (0.551374 iter/s, 36.273s/20 iters), loss = 0.222536
I0828 15:24:51.095193  4902 solver.cpp:238]     Train net output #0: loss = 0.222536 (* 1 = 0.222536 loss)
I0828 15:24:51.095209  4902 sgd_solver.cpp:105] Iteration 2220, lr = 0.0001
I0828 15:25:27.242671  4902 solver.cpp:219] Iteration 2240 (0.553336 iter/s, 36.1444s/20 iters), loss = 0.276938
I0828 15:25:27.242761  4902 solver.cpp:238]     Train net output #0: loss = 0.276938 (* 1 = 0.276938 loss)
I0828 15:25:27.242779  4902 sgd_solver.cpp:105] Iteration 2240, lr = 0.0001
I0828 15:25:42.364490  4902 solver.cpp:331] Iteration 2250, Testing net (#0)
I0828 15:25:46.200425  4902 solver.cpp:398]     Test net output #0: accuracy = 0.902
I0828 15:25:46.200517  4902 solver.cpp:398]     Test net output #1: loss = 0.242019 (* 1 = 0.242019 loss)
I0828 15:26:06.220929  4902 solver.cpp:219] Iteration 2260 (0.513142 iter/s, 38.9755s/20 iters), loss = 0.220323
I0828 15:26:06.221024  4902 solver.cpp:238]     Train net output #0: loss = 0.220323 (* 1 = 0.220323 loss)
I0828 15:26:06.221042  4902 sgd_solver.cpp:105] Iteration 2260, lr = 0.0001
I0828 15:26:42.398345  4902 solver.cpp:219] Iteration 2280 (0.552872 iter/s, 36.1747s/20 iters), loss = 0.188531
I0828 15:26:42.398469  4902 solver.cpp:238]     Train net output #0: loss = 0.188531 (* 1 = 0.188531 loss)
I0828 15:26:42.398512  4902 sgd_solver.cpp:105] Iteration 2280, lr = 0.0001
I0828 15:27:01.093735  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:27:18.502810  4902 solver.cpp:219] Iteration 2300 (0.55399 iter/s, 36.1018s/20 iters), loss = 0.235009
I0828 15:27:18.502898  4902 solver.cpp:238]     Train net output #0: loss = 0.235009 (* 1 = 0.235009 loss)
I0828 15:27:18.502914  4902 sgd_solver.cpp:105] Iteration 2300, lr = 0.0001
I0828 15:27:54.869310  4902 solver.cpp:219] Iteration 2320 (0.550092 iter/s, 36.3576s/20 iters), loss = 0.177678
I0828 15:27:54.869427  4902 solver.cpp:238]     Train net output #0: loss = 0.177678 (* 1 = 0.177678 loss)
I0828 15:27:54.869462  4902 sgd_solver.cpp:105] Iteration 2320, lr = 0.0001
I0828 15:28:30.983104  4902 solver.cpp:219] Iteration 2340 (0.553854 iter/s, 36.1106s/20 iters), loss = 0.231425
I0828 15:28:30.983184  4902 solver.cpp:238]     Train net output #0: loss = 0.231425 (* 1 = 0.231425 loss)
I0828 15:28:30.983201  4902 sgd_solver.cpp:105] Iteration 2340, lr = 0.0001
I0828 15:29:07.271394  4902 solver.cpp:219] Iteration 2360 (0.551191 iter/s, 36.2851s/20 iters), loss = 0.214508
I0828 15:29:07.271494  4902 solver.cpp:238]     Train net output #0: loss = 0.214508 (* 1 = 0.214508 loss)
I0828 15:29:07.271510  4902 sgd_solver.cpp:105] Iteration 2360, lr = 0.0001
I0828 15:29:43.492182  4902 solver.cpp:219] Iteration 2380 (0.55221 iter/s, 36.2181s/20 iters), loss = 0.161933
I0828 15:29:43.492290  4902 solver.cpp:238]     Train net output #0: loss = 0.161933 (* 1 = 0.161933 loss)
I0828 15:29:43.492319  4902 sgd_solver.cpp:105] Iteration 2380, lr = 0.0001
I0828 15:30:19.779319  4902 solver.cpp:219] Iteration 2400 (0.551201 iter/s, 36.2844s/20 iters), loss = 0.192921
I0828 15:30:19.779433  4902 solver.cpp:238]     Train net output #0: loss = 0.192921 (* 1 = 0.192921 loss)
I0828 15:30:19.779465  4902 sgd_solver.cpp:105] Iteration 2400, lr = 0.0001
I0828 15:30:20.296495  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:30:55.980938  4902 solver.cpp:219] Iteration 2420 (0.552519 iter/s, 36.1978s/20 iters), loss = 0.191018
I0828 15:30:55.981034  4902 solver.cpp:238]     Train net output #0: loss = 0.191018 (* 1 = 0.191018 loss)
I0828 15:30:55.981051  4902 sgd_solver.cpp:105] Iteration 2420, lr = 0.0001
I0828 15:31:31.765854  4902 solver.cpp:219] Iteration 2440 (0.558939 iter/s, 35.7821s/20 iters), loss = 0.146296
I0828 15:31:31.765949  4902 solver.cpp:238]     Train net output #0: loss = 0.146296 (* 1 = 0.146296 loss)
I0828 15:31:31.765969  4902 sgd_solver.cpp:105] Iteration 2440, lr = 0.0001
I0828 15:32:08.075510  4902 solver.cpp:219] Iteration 2460 (0.550912 iter/s, 36.3034s/20 iters), loss = 0.218163
I0828 15:32:08.075614  4902 solver.cpp:238]     Train net output #0: loss = 0.218163 (* 1 = 0.218163 loss)
I0828 15:32:08.075631  4902 sgd_solver.cpp:105] Iteration 2460, lr = 0.0001
I0828 15:32:44.326467  4902 solver.cpp:219] Iteration 2480 (0.551758 iter/s, 36.2478s/20 iters), loss = 0.204741
I0828 15:32:44.326587  4902 solver.cpp:238]     Train net output #0: loss = 0.204741 (* 1 = 0.204741 loss)
I0828 15:32:44.326619  4902 sgd_solver.cpp:105] Iteration 2480, lr = 0.0001
I0828 15:33:17.377383  4902 solver.cpp:331] Iteration 2500, Testing net (#0)
I0828 15:33:21.177613  4902 solver.cpp:398]     Test net output #0: accuracy = 0.905
I0828 15:33:21.177700  4902 solver.cpp:398]     Test net output #1: loss = 0.223144 (* 1 = 0.223144 loss)
I0828 15:33:21.710664  4960 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:33:22.938133  4902 solver.cpp:219] Iteration 2500 (0.518021 iter/s, 38.6085s/20 iters), loss = 0.2283
I0828 15:33:22.938223  4902 solver.cpp:238]     Train net output #0: loss = 0.2283 (* 1 = 0.2283 loss)
I0828 15:33:22.938241  4902 sgd_solver.cpp:105] Iteration 2500, lr = 0.0001
I0828 15:33:39.877918  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:33:59.066779  4902 solver.cpp:219] Iteration 2520 (0.553587 iter/s, 36.128s/20 iters), loss = 0.246138
I0828 15:33:59.066890  4902 solver.cpp:238]     Train net output #0: loss = 0.246138 (* 1 = 0.246138 loss)
I0828 15:33:59.066920  4902 sgd_solver.cpp:105] Iteration 2520, lr = 0.0001
I0828 15:34:35.191989  4902 solver.cpp:219] Iteration 2540 (0.553679 iter/s, 36.122s/20 iters), loss = 0.215179
I0828 15:34:35.192090  4902 solver.cpp:238]     Train net output #0: loss = 0.215179 (* 1 = 0.215179 loss)
I0828 15:34:35.192116  4902 sgd_solver.cpp:105] Iteration 2540, lr = 0.0001
I0828 15:35:11.403245  4902 solver.cpp:219] Iteration 2560 (0.552343 iter/s, 36.2094s/20 iters), loss = 0.231285
I0828 15:35:11.403362  4902 solver.cpp:238]     Train net output #0: loss = 0.231285 (* 1 = 0.231285 loss)
I0828 15:35:11.403394  4902 sgd_solver.cpp:105] Iteration 2560, lr = 0.0001
I0828 15:35:47.746881  4902 solver.cpp:219] Iteration 2580 (0.55035 iter/s, 36.3405s/20 iters), loss = 0.232078
I0828 15:35:47.746989  4902 solver.cpp:238]     Train net output #0: loss = 0.232078 (* 1 = 0.232078 loss)
I0828 15:35:47.747020  4902 sgd_solver.cpp:105] Iteration 2580, lr = 0.0001
I0828 15:36:23.812655  4902 solver.cpp:219] Iteration 2600 (0.554641 iter/s, 36.0593s/20 iters), loss = 0.24033
I0828 15:36:23.812764  4902 solver.cpp:238]     Train net output #0: loss = 0.24033 (* 1 = 0.24033 loss)
I0828 15:36:23.812794  4902 sgd_solver.cpp:105] Iteration 2600, lr = 0.0001
I0828 15:36:57.187968  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:37:00.136297  4902 solver.cpp:219] Iteration 2620 (0.550655 iter/s, 36.3204s/20 iters), loss = 0.225868
I0828 15:37:00.136409  4902 solver.cpp:238]     Train net output #0: loss = 0.225868 (* 1 = 0.225868 loss)
I0828 15:37:00.136438  4902 sgd_solver.cpp:105] Iteration 2620, lr = 0.0001
I0828 15:37:36.271021  4902 solver.cpp:219] Iteration 2640 (0.553494 iter/s, 36.1341s/20 iters), loss = 0.161964
I0828 15:37:36.271118  4902 solver.cpp:238]     Train net output #0: loss = 0.161964 (* 1 = 0.161964 loss)
I0828 15:37:36.271136  4902 sgd_solver.cpp:105] Iteration 2640, lr = 0.0001
I0828 15:38:11.805446  4902 solver.cpp:219] Iteration 2660 (0.56288 iter/s, 35.5316s/20 iters), loss = 0.176609
I0828 15:38:11.805549  4902 solver.cpp:238]     Train net output #0: loss = 0.176609 (* 1 = 0.176609 loss)
I0828 15:38:11.805567  4902 sgd_solver.cpp:105] Iteration 2660, lr = 0.0001
I0828 15:38:43.810269  4902 solver.cpp:219] Iteration 2680 (0.624918 iter/s, 32.0042s/20 iters), loss = 0.209036
I0828 15:38:43.810385  4902 solver.cpp:238]     Train net output #0: loss = 0.209036 (* 1 = 0.209036 loss)
I0828 15:38:43.810416  4902 sgd_solver.cpp:105] Iteration 2680, lr = 0.0001
I0828 15:39:19.834185  4902 solver.cpp:219] Iteration 2700 (0.555228 iter/s, 36.0212s/20 iters), loss = 0.18978
I0828 15:39:19.834283  4902 solver.cpp:238]     Train net output #0: loss = 0.18978 (* 1 = 0.18978 loss)
I0828 15:39:19.834300  4902 sgd_solver.cpp:105] Iteration 2700, lr = 0.0001
I0828 15:39:55.878137  4902 solver.cpp:219] Iteration 2720 (0.55492 iter/s, 36.0412s/20 iters), loss = 0.150769
I0828 15:39:55.878238  4902 solver.cpp:238]     Train net output #0: loss = 0.150769 (* 1 = 0.150769 loss)
I0828 15:39:55.878257  4902 sgd_solver.cpp:105] Iteration 2720, lr = 0.0001
I0828 15:40:10.980473  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:40:32.169894  4902 solver.cpp:219] Iteration 2740 (0.551131 iter/s, 36.289s/20 iters), loss = 0.183005
I0828 15:40:32.169982  4902 solver.cpp:238]     Train net output #0: loss = 0.183005 (* 1 = 0.183005 loss)
I0828 15:40:32.169998  4902 sgd_solver.cpp:105] Iteration 2740, lr = 0.0001
I0828 15:40:47.190318  4902 solver.cpp:331] Iteration 2750, Testing net (#0)
I0828 15:40:50.956221  4902 solver.cpp:398]     Test net output #0: accuracy = 0.906
I0828 15:40:50.956301  4902 solver.cpp:398]     Test net output #1: loss = 0.242108 (* 1 = 0.242108 loss)
I0828 15:41:11.138542  4902 solver.cpp:219] Iteration 2760 (0.513262 iter/s, 38.9665s/20 iters), loss = 0.199008
I0828 15:41:11.138646  4902 solver.cpp:238]     Train net output #0: loss = 0.199008 (* 1 = 0.199008 loss)
I0828 15:41:11.138664  4902 sgd_solver.cpp:105] Iteration 2760, lr = 0.0001
I0828 15:41:47.310154  4902 solver.cpp:219] Iteration 2780 (0.552969 iter/s, 36.1684s/20 iters), loss = 0.143493
I0828 15:41:47.310278  4902 solver.cpp:238]     Train net output #0: loss = 0.143493 (* 1 = 0.143493 loss)
I0828 15:41:47.310309  4902 sgd_solver.cpp:105] Iteration 2780, lr = 0.0001
I0828 15:42:23.397086  4902 solver.cpp:219] Iteration 2800 (0.554259 iter/s, 36.0842s/20 iters), loss = 0.176307
I0828 15:42:23.397179  4902 solver.cpp:238]     Train net output #0: loss = 0.176307 (* 1 = 0.176307 loss)
I0828 15:42:23.397194  4902 sgd_solver.cpp:105] Iteration 2800, lr = 0.0001
I0828 15:42:59.455147  4902 solver.cpp:219] Iteration 2820 (0.554703 iter/s, 36.0553s/20 iters), loss = 0.207569
I0828 15:42:59.455272  4902 solver.cpp:238]     Train net output #0: loss = 0.207569 (* 1 = 0.207569 loss)
I0828 15:42:59.455307  4902 sgd_solver.cpp:105] Iteration 2820, lr = 0.0001
I0828 15:43:30.896253  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:43:35.712321  4902 solver.cpp:219] Iteration 2840 (0.551681 iter/s, 36.2529s/20 iters), loss = 0.198885
I0828 15:43:35.712410  4902 solver.cpp:238]     Train net output #0: loss = 0.198885 (* 1 = 0.198885 loss)
I0828 15:43:35.712427  4902 sgd_solver.cpp:105] Iteration 2840, lr = 0.0001
I0828 15:44:11.763495  4902 solver.cpp:219] Iteration 2860 (0.554809 iter/s, 36.0484s/20 iters), loss = 0.20471
I0828 15:44:11.763595  4902 solver.cpp:238]     Train net output #0: loss = 0.20471 (* 1 = 0.20471 loss)
I0828 15:44:11.763612  4902 sgd_solver.cpp:105] Iteration 2860, lr = 0.0001
I0828 15:44:47.836539  4902 solver.cpp:219] Iteration 2880 (0.55448 iter/s, 36.0698s/20 iters), loss = 0.140388
I0828 15:44:47.836632  4902 solver.cpp:238]     Train net output #0: loss = 0.140388 (* 1 = 0.140388 loss)
I0828 15:44:47.836648  4902 sgd_solver.cpp:105] Iteration 2880, lr = 0.0001
I0828 15:45:23.993695  4902 solver.cpp:219] Iteration 2900 (0.553182 iter/s, 36.1544s/20 iters), loss = 0.18657
I0828 15:45:23.993789  4902 solver.cpp:238]     Train net output #0: loss = 0.18657 (* 1 = 0.18657 loss)
I0828 15:45:23.993803  4902 sgd_solver.cpp:105] Iteration 2900, lr = 0.0001
I0828 15:46:00.159207  4902 solver.cpp:219] Iteration 2920 (0.553055 iter/s, 36.1628s/20 iters), loss = 0.191797
I0828 15:46:00.159297  4902 solver.cpp:238]     Train net output #0: loss = 0.191797 (* 1 = 0.191797 loss)
I0828 15:46:00.159314  4902 sgd_solver.cpp:105] Iteration 2920, lr = 0.0001
I0828 15:46:36.254144  4902 solver.cpp:219] Iteration 2940 (0.554144 iter/s, 36.0917s/20 iters), loss = 0.202733
I0828 15:46:36.254247  4902 solver.cpp:238]     Train net output #0: loss = 0.202733 (* 1 = 0.202733 loss)
I0828 15:46:36.254266  4902 sgd_solver.cpp:105] Iteration 2940, lr = 0.0001
I0828 15:46:47.724879  4958 data_layer.cpp:73] Restarting data prefetching from start.
I0828 15:47:12.477277  4902 solver.cpp:219] Iteration 2960 (0.552175 iter/s, 36.2204s/20 iters), loss = 0.191995
I0828 15:47:12.477390  4902 solver.cpp:238]     Train net output #0: loss = 0.191995 (* 1 = 0.191995 loss)
I0828 15:47:12.477422  4902 sgd_solver.cpp:105] Iteration 2960, lr = 0.0001
I0828 15:47:48.369858  4902 solver.cpp:219] Iteration 2980 (0.557263 iter/s, 35.8897s/20 iters), loss = 0.207406
I0828 15:47:48.369951  4902 solver.cpp:238]     Train net output #0: loss = 0.207406 (* 1 = 0.207406 loss)
I0828 15:47:48.369968  4902 sgd_solver.cpp:105] Iteration 2980, lr = 0.0001
I0828 15:48:21.550777  4902 solver.cpp:331] Iteration 3000, Testing net (#0)
I0828 15:48:25.332124  4902 solver.cpp:398]     Test net output #0: accuracy = 0.92
I0828 15:48:25.332206  4902 solver.cpp:398]     Test net output #1: loss = 0.210833 (* 1 = 0.210833 loss)
I0828 15:48:27.179967  4902 solver.cpp:219] Iteration 3000 (0.515357 iter/s, 38.8081s/20 iters), loss = 0.190791
I0828 15:48:27.180057  4902 solver.cpp:238]     Train net output #0: loss = 0.190791 (* 1 = 0.190791 loss)
I0828 15:48:27.180075  4902 sgd_solver.cpp:105] Iteration 3000, lr = 1e-05
data	(256, 3, 227, 227)
label	(256,)
conv1	(256, 96, 55, 55)
pool1	(256, 96, 27, 27)
norm1	(256, 96, 27, 27)
conv2	(256, 256, 27, 27)
pool2	(256, 256, 13, 13)
norm2	(256, 256, 13, 13)
conv3	(256, 384, 13, 13)
conv4	(256, 384, 13, 13)
conv5	(256, 256, 13, 13)
pool5	(256, 256, 6, 6)
fc6	(256, 4096)
fc7	(256, 4096)
fc8	(256, 2)
loss	()
conv1	(96, 3, 11, 11) (96,)
conv2	(256, 48, 5, 5) (256,)
conv3	(384, 256, 3, 3) (384,)
conv4	(384, 192, 3, 3) (384,)
conv5	(256, 192, 3, 3) (256,)
fc6	(4096, 9216) (4096,)
fc7	(4096, 4096) (4096,)
fc8	(2, 4096) (2,)
